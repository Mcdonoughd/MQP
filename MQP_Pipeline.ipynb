{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQP Pipeline\n",
    "\n",
    "\n",
    "## By Daniel McDonough & Surya Vadivazhagu\n",
    "\n",
    "This notebook includes all of our scripts into one easy pipeline for easy editing and swapping of components.\n",
    "Full paper can be viewed at: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Raw Datasets\n",
    "\n",
    "\n",
    "Remember to unzip and export the original folder out.\n",
    "\n",
    "\n",
    "Merge the contents of Movie1_part1 and Movie1_part2 into the same Movie1 folder\n",
    "\n",
    "\n",
    "[Manning_Simple](https://www.kaggle.com/coffeeoverflow/manning-simple)\n",
    "\n",
    "\n",
    "[Manning_Movie1](https://www.kaggle.com/coffeeoverflow/manning-movie1-part1)\n",
    "\n",
    "\n",
    "[Manning_Movie2](https://www.kaggle.com/coffeeoverflow/manning-movie2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import mahotas\n",
    "import cv2\n",
    "import shutil\n",
    "import pymrmr\n",
    "from scipy import ndimage as ndi\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import exposure\n",
    "from skimage import morphology\n",
    "from skimage import color\n",
    "from skimage.measure import label\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.morphology import watershed\n",
    "from skimage.morphology import extrema\n",
    "from skimage.transform import resize\n",
    "import keras\n",
    "import keras_resnet.models\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Organized/Manning_Simple\n",
      "./Organized/Manning_Movie1\n",
      "./Organized/Manning_Movie2\n"
     ]
    }
   ],
   "source": [
    "# given a path and foldername, this function checks if it exists already and makes a folder\n",
    "def makefolder(path,foldername):\n",
    "    homepath = path+foldername\n",
    "    # if home path already exists then delete it\n",
    "    if os.path.isdir(homepath):\n",
    "        shutil.rmtree(homepath)\n",
    "\n",
    "    # make the home path\n",
    "    os.mkdir(homepath)\n",
    "    print(homepath)\n",
    "    return homepath\n",
    "\n",
    "\n",
    "# Make folders required for data storage\n",
    "def makeFolders(folders = None):\n",
    "    if folders is None:\n",
    "        folders = [\"./Crops\",\"./LOG\",\"./Gabor\",\"./HOG\",\"./SIFT\",\"./Dataset\"]\n",
    "    for path in folders:\n",
    "        if os.path.exists(path):\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                for file in files:\n",
    "                    os.remove(os.path.join(root, file))\n",
    "        else:\n",
    "            os.mkdir(path)\n",
    "\n",
    "\n",
    "makefolder(\"./Organized\",\"/Manning_Simple\")\n",
    "makefolder(\"./Organized\",\"/Manning_Movie1\")\n",
    "makefolder(\"./Organized\",\"/Manning_Movie2\")\n",
    "Dataset_location = \"./Dataset\"\n",
    "makeFolders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Raw Dataset to Overlayed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Organized/Manning_Simple/Well C3\n",
      "./Organized/Manning_Simple/Well C3/XY1\n",
      "./Organized/Manning_Simple/Well C3/XY1/Overlay\n",
      "./Organized/Manning_Simple/Well C3/XY2\n",
      "./Organized/Manning_Simple/Well C3/XY2/Overlay\n",
      "./Organized/Manning_Simple/Well C3/XY3\n",
      "./Organized/Manning_Simple/Well C3/XY3/Overlay\n",
      "./Organized/Manning_Simple/Well C3/XY4\n",
      "./Organized/Manning_Simple/Well C3/XY4/Overlay\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-be8ea8e46553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0moriginalpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./Manning_Simple\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0morganizedpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./Organized/Manning_Simple\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0msortSimple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginalpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morganizedpath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sort by wells method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-be8ea8e46553>\u001b[0m in \u001b[0;36msortSimple\u001b[0;34m(homepath, organizedpath)\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0;31m# Overlay the red and green and save it to the overlay image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mcombinedFilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlayfolderpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_filename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".tif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0mcombineImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredImageLocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreenImageLocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombinedFilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-be8ea8e46553>\u001b[0m in \u001b[0;36mcombineImages\u001b[0;34m(redLocation, greenLocation, filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# given two images images, combine the red and green channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcombineImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredLocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgreenLocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mRedImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mGreenImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreenLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  make folders based on the Movie named data\n",
    "def makeMovieFolders(foldername):\n",
    "    path = \"./Organized/\"\n",
    "    homepath = makefolder(path,foldername)\n",
    "    overlay =makefolder(homepath, \"/Overlay\")\n",
    "    return (homepath,green,red,overlay)\n",
    "\n",
    "\n",
    "# given two images images, combine the red and green channels\n",
    "def combineImages(redLocation,greenLocation,filename):\n",
    "    RedImage = cv2.imread(redLocation)\n",
    "    GreenImage = cv2.imread(greenLocation)\n",
    "\n",
    "    height, width, layers = RedImage.shape  # height, width, layers of an image\n",
    "    zeroImgMatrix = np.zeros((height, width), dtype=\"uint8\")  # matrix of zeros (black)\n",
    "\n",
    "    # The OpenCV image sequence is Blue(B),Green(G) and Red(R)\n",
    "    (BR, GR, RR) = cv2.split(RedImage)\n",
    "    (BG, GG, RG) = cv2.split(GreenImage)\n",
    "\n",
    "    Merge = cv2.merge([zeroImgMatrix, GG,RR ])\n",
    "    \n",
    "    cv2.imwrite(filename, Merge)\n",
    "    \n",
    "    \n",
    "# sort files based on the Movie1 Dataset filenames\n",
    "def sortMovies(name,originalpath):\n",
    "    (homepath, green, red, overlay) = makeMovieFolders(name)\n",
    "    cells = os.listdir(originalpath)\n",
    "    cells.sort()\n",
    "    for file in cells:\n",
    "        channel = file[-5]  # channel number of a file\n",
    "        # if the channel is red\n",
    "        if channel == str(1):\n",
    "            basename = file[:-5]  # name of the file without #.tif\n",
    "            # find the corosponding green image\n",
    "            greenImageLocation = os.path.join(originalpath,basename+\"2.tif\")\n",
    "            if os.path.isfile(greenImageLocation):\n",
    "           \n",
    "                # Copy the red file to the red channel\n",
    "                redImageLocation = os.path.join(originalpath, file)\n",
    "                \n",
    "                combinedFilename = os.path.join(overlay,basename+\".tif\")\n",
    "                combineImages(red+\"/\"+basename+\"1.tif\",green+\"/\"+basename+\"2.tif\",combinedFilename)\n",
    "\n",
    "            else:\n",
    "                print(\"This image does not have a corresponding green channel image, skipping...\")\n",
    "\n",
    "# sort files based on the Movie2 Dataset filenames\n",
    "def sortMovies2(name,originalpath):\n",
    "\n",
    "    (homepath, green, red, overlay) = makeMovieFolders(name)\n",
    "    cells = os.listdir(originalpath)\n",
    "    cells.sort()\n",
    "    for file in cells:\n",
    "\n",
    "        channel = file[-5]  # channel number of a file\n",
    "\n",
    "        # if the channel is red\n",
    "        if channel == str(2):\n",
    "            basename = file[:-5]  # name of the file without #.tif\n",
    "\n",
    "            # find the corosponding green image\n",
    "            greenImageLocation = os.path.join(originalpath,basename+\"1.tif\")\n",
    "\n",
    "            if os.path.isfile(greenImageLocation):\n",
    "                \n",
    "                # Copy the red file to the red channel\n",
    "                redImageLocation = os.path.join(originalpath, file)\n",
    "                \n",
    "                combinedFilename = os.path.join(overlay,basename+\".tif\")\n",
    "                combineImages(red+\"/\"+basename+\"2.tif\",green+\"/\"+basename+\"1.tif\",combinedFilename)\n",
    "\n",
    "            else:\n",
    "                print(\"This image does not have a corresponding green channel image, skipping...\")\n",
    "\n",
    "    \n",
    "# sort files based on the a Dataset with Wells Descriptors\n",
    "def sortSimple(homepath,organizedpath):\n",
    "    # in the dataset there are wells\n",
    "    for well in os.listdir(homepath):\n",
    "        currdir = os.path.join(homepath,well)\n",
    "        newfolderpath = makefolder(organizedpath,\"/\"+well)\n",
    "\n",
    "        # there are 8 sections in a well (1 to 8)\n",
    "        for i in range(1,9):\n",
    "            pos = \"XY\"+str(i)\n",
    "            posfolderpath = makefolder(newfolderpath, \"/\"+pos)\n",
    "            overlayfolderpath = makefolder(posfolderpath, \"/Overlay\")\n",
    "\n",
    "            # get list of all RED images in the directory at this position, in this well\n",
    "            Redpics = [file for file in os.listdir(currdir) if pos in file and \"TxRED.tif\" in file]\n",
    "            # get list of all GREEN images in the directory at this position\n",
    "            Greenpics = [file for file in os.listdir(currdir) if pos in file and \"FITC.tif\" in file]\n",
    "            # Check that there is a corresponding green image to each red image\n",
    "            for file in Redpics:\n",
    "                # get equalivalent green channel file name\n",
    "                base_filename = file.rsplit(\"_\", 1)\n",
    "                green_filename = base_filename[0] +\"_FITC.tif\"\n",
    "\n",
    "                # if equal filename exists...\n",
    "                if green_filename in Greenpics:\n",
    "\n",
    "                    #copy green image to organized folder\n",
    "                    greenImageLocation = os.path.join(currdir, green_filename)\n",
    "                    \n",
    "                    # copy red image to the red orgainzed folder\n",
    "                    redImageLocation = os.path.join(currdir, file)\n",
    "                    \n",
    "                    # Overlay the red and green and save it to the overlay image\n",
    "                    combinedFilename = os.path.join(overlayfolderpath, base_filename[0] + \".tif\")\n",
    "                    combineImages(redImageLocation, greenImageLocation, combinedFilename)\n",
    "\n",
    "                    \n",
    "# Sort Raw Movies into overlays                  \n",
    "\n",
    "originalpath = \"./Manning_Simple\"\n",
    "organizedpath = \"./Organized/Manning_Simple\"                  \n",
    "sortSimple(originalpath,organizedpath)  # sort by wells method \n",
    "\n",
    "\n",
    "# originalpath = \"./Manning_Movie1\"\n",
    "# organizedpath = \"./Organized/Manning_Movie1\"  \n",
    "# sortMovies(name,originalpath)  # sort by movies method\n",
    "\n",
    "\n",
    "# originalpath = \"./Manning_Movie2\"\n",
    "# organizedpath = \"./Organized/Manning_Movie2\"  \n",
    "# sortMovies2(name,originalpath)  # sort by wells method\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important\n",
    "From the generated overlays we manually selected 1 image from each overlay folder and placed them into the Dataset folder. This was done to prevent prepresenting a single cell multiple times.\n",
    "\n",
    "\n",
    "The Dataset folder is used for the rest of the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Green Haze removal\n",
    "Here we do an average subtraction of the green haze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dehaze the green channel\n",
    "def dehaze(g):\n",
    "    # find average value\n",
    "    avg = np.average(g)\n",
    "\n",
    "    # I - avg\n",
    "    chosen_sub_a = g - avg\n",
    "\n",
    "    # make sure no negatives\n",
    "    chosen_sub_a.astype(int)\n",
    "    chosen_sub_a = chosen_sub_a.clip(min=0)\n",
    "    return chosen_sub_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gamma Correction\n",
    "Here we do gamma correction on the red channel with y=1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the gamma of a given image\n",
    "def adjust_gamma(r, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(r, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Nuclei Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate an image given an angle\n",
    "def rotate_bound(image, angle):\n",
    "    \n",
    "    # grab the dimensions of the image and then determine the \n",
    "    # center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    \n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    \n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "    \n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "    # perform the actual rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale Image Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale image   \n",
    "def bilinear_upscale(image,rate=2):\n",
    "    rate = 2\n",
    "    img_linear_x = int(image.shape[1] * rate)\n",
    "    img_linear_y = int(image.shape[0] * rate)\n",
    "    pil_im = Image.fromarray(image)\n",
    "    image = pil_im.resize((img_linear_x, img_linear_y), Image.BILINEAR)  # bilinear interpolation\n",
    "    image = np.asarray(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad Image to uniform size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad an image with zeros given the image and the new size\n",
    "def padImage(img,newhight,newwidth):\n",
    "    h,w = img.shape\n",
    "    width_diff = newwidth - w\n",
    "    height_diff = newhight - h\n",
    "\n",
    "    th = int(math.floor(height_diff/2))\n",
    "    bh = int(math.ceil(height_diff / 2))\n",
    "    rw = int(math.ceil(width_diff / 2))\n",
    "    lw = int(math.ceil(width_diff / 2))\n",
    "\n",
    "    new_img = np.pad(img,[(th,bh),(rw,lw)],mode='constant',constant_values=0)\n",
    "    return new_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Centroid, Major axis, Minor Axis, Eccentricity, and Rotation angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Centroid, Major axis, Minor Axis, Eccentricity, and Rotation angles\n",
    "def get_axis(cnt):\n",
    "\n",
    "    if len(cnt) < 5:\n",
    "        return 0,0,0,0,0,0,0\n",
    "\n",
    "    (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)\n",
    "\n",
    "    a = ma / 2\n",
    "    b = MA / 2\n",
    "\n",
    "    ecc = np.sqrt(a ** 2 - b ** 2) / a\n",
    "\n",
    "    maj_angle = int(round(angle))\n",
    "    min_angle = maj_angle - 45\n",
    "    if min_angle < 0:\n",
    "        min_angle = min_angle + 180\n",
    "\n",
    "    return int(round(x)),int(round(y)),int(round(MA)),int(round(ma)),maj_angle,min_angle, ecc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zernlike Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Zernlike Moments\n",
    "def fd_Zern(img,radius):\n",
    "    zern = mahotas.features.zernike_moments(img, radius)\n",
    "    return zern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laplacian of Gaussian of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian of Gaussian of an image\n",
    "def fd_LoG(gray_img, sigma=1., kappa=0.75, pad=False):\n",
    "    \"\"\"\n",
    "    Applies Laplacian of Gaussians to grayscale image.\n",
    "\n",
    "    :param gray_img: image to apply LoG to\n",
    "    :param sigma:    Gauss sigma of Gaussian applied to image, <= 0. for none\n",
    "    :param kappa:    difference threshold as factor to mean of image values, <= 0 for none\n",
    "    :param pad:      flag to pad output w/ zero border, keeping input image size\n",
    "    \"\"\"\n",
    "    assert len(gray_img.shape) == 2\n",
    "    img = cv2.GaussianBlur(gray_img, (0, 0), sigma) if 0. < sigma else gray_img\n",
    "    img = cv2.Laplacian(img, cv2.CV_64F)\n",
    "    rows, cols = img.shape[:2]\n",
    "    \n",
    "    # min/max of 3x3-neighbourhoods\n",
    "    min_map = np.minimum.reduce(list(img[r:rows-2+r, c:cols-2+c]\n",
    "                                     for r in range(3) for c in range(3)))\n",
    "    max_map = np.maximum.reduce(list(img[r:rows-2+r, c:cols-2+c]\n",
    "                                     for r in range(3) for c in range(3)))\n",
    "    \n",
    "    # bool matrix for image value positiv (w/out border pixels)\n",
    "    pos_img = 0 < img[1:rows-1, 1:cols-1]\n",
    "    \n",
    "    # bool matrix for min < 0 and 0 < image pixel\n",
    "    neg_min = min_map < 0\n",
    "    neg_min[1 - pos_img] = 0\n",
    "    \n",
    "    # bool matrix for 0 < max and image pixel < 0\n",
    "    pos_max = 0 < max_map\n",
    "    pos_max[pos_img] = 0\n",
    "    \n",
    "    # sign change at pixel?\n",
    "    zero_cross = neg_min + pos_max\n",
    "    \n",
    "    # values: max - min, scaled to 0--255; set to 0 for no sign change\n",
    "    value_scale = 255. / max(1., img.max() - img.min())\n",
    "    values = value_scale * (max_map - min_map)\n",
    "    values[1 - zero_cross] = 0.\n",
    "    \n",
    "    # optional thresholding\n",
    "    if 0. <= kappa:\n",
    "        thresh = float(np.absolute(img).mean()) * kappa\n",
    "        values[values < thresh] = 0.\n",
    "    log_img = values.astype(np.uint8)\n",
    "    if pad:\n",
    "        log_img = np.pad(log_img, pad_width=1, mode='constant', constant_values=0)\n",
    "    return log_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Haralick Texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-2: Haralick Texture\n",
    "def fd_haralick(image):\n",
    "    # compute the haralick texture feature vector\n",
    "    haralick = mahotas.features.haralick(image).mean(axis=0)\n",
    "    # return the result\n",
    "    return haralick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hu Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hu moments (similar to zern)\n",
    "def fd_hu_moments(image):\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the aspect ratio of the min bounding box of a nuclei\n",
    "def fd_aspect_ratio(cnt):\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = float(w)/h\n",
    "    return aspect_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the extent a shape is concave or convex \n",
    "def fd_solidity(cnt):\n",
    "    area = cv2.contourArea(cnt)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solid = float(area)/hull_area\n",
    "    return solid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gabor Wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate GaborWavelet descriptor\n",
    "def fd_GaborWavelet(img):\n",
    "    filters = []\n",
    "    ksize = 31\n",
    "    for theta in np.arange(0, np.pi, np.pi / 16):\n",
    "        kern = cv2.getGaborKernel((ksize, ksize), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    kern /= 1.5 * kern.sum()\n",
    "    filters.append(kern)\n",
    "    \n",
    "    accum = np.zeros_like(img)\n",
    "    for kern in filters:\n",
    "        fimg = cv2.filter2D(img, cv2.CV_8UC3, kern)\n",
    "    np.maximum(accum, fimg, accum)\n",
    "    return accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculates the ratio between the nuclei's contour and bounding rectangle\n",
    "def fd_extent(cnt):\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    return extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SIFT descriptors\n",
    "def fd_SIFT(img):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(rot_single_nuclei, None)\n",
    "    return des\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Oriented Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of oriented Gradients \n",
    "def fd_HOG(img):\n",
    "    (H, hogImage) = hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                                cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2-Hys\",\n",
    "                                visualize=True)\n",
    "    hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255))\n",
    "    hogImage = hogImage.astype(\"uint8\")\n",
    "\n",
    "    return hogImage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equivalent Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculated the Equivalent Diameter of min circle packing\n",
    "def fd_Equi_diameter(cnt):\n",
    "    area = cv2.contourArea(cnt)\n",
    "    equi_diameter = np.sqrt(4*area/np.pi)\n",
    "    return int(round(equi_diameter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roundness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the roundness of a contour\n",
    "def fd_roundness(cnt):\n",
    "    moments = cv2.moments(cnt)\n",
    "    length = cv2.arcLength(cnt, True)\n",
    "    k = (length * length) / (moments['m00'] * 4 * np.pi)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liner Binary Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate LBP descriptors\n",
    "def fd_linearbinarypattern(img):\n",
    "    height, width = img.shape\n",
    "    img_lbp = np.zeros((height, width, 3), np.uint8)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            img_lbp[i, j] = lbp_calculated_pixel(img, i, j)\n",
    "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
    "    hist_lbp = [int(i) for i in hist_lbp]\n",
    "    return hist_lbp   \n",
    "\n",
    "def lbp_calculated_pixel(img, x, y):\n",
    "    '''\n",
    "     64 | 128 |   1\n",
    "    ----------------\n",
    "     32 |   0 |   2\n",
    "    ----------------\n",
    "     16 |   8 |   4\n",
    "    '''\n",
    "    center = img[x][y]\n",
    "    val_ar = []\n",
    "    val_ar.append(get_pixel(img, center, x - 1, y + 1))  # top_right\n",
    "    val_ar.append(get_pixel(img, center, x, y + 1))  # right\n",
    "    val_ar.append(get_pixel(img, center, x + 1, y + 1))  # bottom_right\n",
    "    val_ar.append(get_pixel(img, center, x + 1, y))  # bottom\n",
    "    val_ar.append(get_pixel(img, center, x + 1, y - 1))  # bottom_left\n",
    "    val_ar.append(get_pixel(img, center, x, y - 1))  # left\n",
    "    val_ar.append(get_pixel(img, center, x - 1, y - 1))  # top_left\n",
    "    val_ar.append(get_pixel(img, center, x - 1, y))  # top\n",
    "\n",
    "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    val = 0\n",
    "    for i in range(len(val_ar)):\n",
    "        val += val_ar[i] * power_val[i]\n",
    "    return val\n",
    "\n",
    "def get_pixel(img, center, x, y):\n",
    "    new_value = 0\n",
    "    try:\n",
    "        if img[x][y] >= center:\n",
    "            new_value = 1\n",
    "    except:\n",
    "        pass\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store ND Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store ND array to a dictionary\n",
    "def StoreNDArray(dict,featurename,data):\n",
    "    if data is not None:\n",
    "        if not type(data) == list:\n",
    "            data = data.flatten()\n",
    "        for idx,val in enumerate(data):\n",
    "            dict[featurename+str(idx)] = val\n",
    "    else:\n",
    "        dict[featurename + str(0)] = 0\n",
    "\n",
    "\n",
    "def StoreHaralickFeature(dict,data):\n",
    "    haralick_featres = [\"ang second moment\",\"contrast\",\"correlation\",\"sum of squares: varience\", \"inverse Diff moment\",\n",
    "                        \"sum average\",\"sum varience\",\"sum entropy\",\"entropy\", \"diff varience\",\"dif entropy\",\"measure of corro 1\", \"measure of corro 2\"]\n",
    "    for idx,val in enumerate(data):\n",
    "        dict[haralick_featres[idx]] = val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuclei Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the nuclei image channel, find nuclei\n",
    "def detect_NUCLEI(r):\n",
    "    \n",
    "    # Gamma correction   \n",
    "    r = adjust_gamma(r, gamma=1.5)\n",
    "\n",
    "    # Otsu's thresholding\n",
    "    ret2, th2 = cv2.threshold(r, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # These contours are then filled using mathematical morphology.\n",
    "    fill_masks = ndi.binary_fill_holes(th2)\n",
    "\n",
    "    # Small spurious objects are easily removed by setting a minimum size for valid objects.\n",
    "    cleaned_image = morphology.remove_small_objects(fill_masks, 150)\n",
    "    \n",
    "    # Perform Distance Transform     \n",
    "    D = ndi.distance_transform_edt(cleaned_image)\n",
    "    localMax = peak_local_max(D, indices=False, min_distance=20, labels=cleaned_image)\n",
    "    \n",
    "    # perform a connected component analysis on the local peaks,\n",
    "    # using 8-connectivity, then appy the Watershed algorithm\n",
    "    markers = ndi.label(localMax, structure=np.ones((3, 3)))[0]\n",
    "    labels = watershed(-D, markers, mask=cleaned_image)\n",
    "    print(\"[INFO] {} unique segments found\".format(len(np.unique(labels)) - 1))\n",
    "\n",
    "    # Un comment to bypass watershed\n",
    "    # labels, num = ndi.label(cleaned_image, structure=np.ones((3, 3)))\n",
    "\n",
    "    # remove edge nuclei\n",
    "    labels_image = clear_border(labels)\n",
    "    \n",
    "    # recount labels\n",
    "    number_regions = np.delete(np.unique(labels_image), 0)\n",
    "\n",
    "    return labels_image, number_regions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foci Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive median filter of an image\n",
    "def adaptive_median_filter(img,sMax):\n",
    "    newimg = img.copy()\n",
    "    height, width = img.shape[:2]\n",
    "    filterSize = 3\n",
    "    borderSize = sMax // 2\n",
    "    imgMax = img[(0, 0)]\n",
    "    mid = (filterSize * filterSize) // 2\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            if (imgMax < img[j,i]):\n",
    "                imgMax = img[j,i]\n",
    "\n",
    "    for i in range(borderSize, width - borderSize):\n",
    "        for j in range(borderSize, height - borderSize):\n",
    "            members = [imgMax] * (sMax * sMax)\n",
    "            filterSize = 3\n",
    "            zxy = img[j,i]\n",
    "            result = zxy\n",
    "            while (filterSize <= sMax):\n",
    "                borderS = filterSize // 2\n",
    "                for k in range(filterSize):\n",
    "                    for t in range(filterSize):\n",
    "                        members[k * filterSize + t] = img[j + t - borderS,i + k - borderS]\n",
    "                        # print(members[k*filterSize+t])\n",
    "                members.sort()\n",
    "                med = (filterSize * filterSize) // 2\n",
    "                zmin = members[0]\n",
    "                zmax = members[(filterSize - 1) * (filterSize + 1)]\n",
    "                zmed = members[med]\n",
    "                if (zmed < zmax and zmed > zmin):\n",
    "                    if (zxy > zmin and zxy < zmax):\n",
    "                        result = zxy\n",
    "                    else:\n",
    "                        result = zmed\n",
    "                    break\n",
    "                else:\n",
    "                    filterSize += 2\n",
    "\n",
    "            newimg[j,i] = result\n",
    "    return newimg\n",
    "\n",
    "# produce a top_hat transform from a cell\n",
    "def top_hat_transform(img,kernel_size):\n",
    "    # Structuring element\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    # Apply the top hat transform\n",
    "    tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "    return tophat\n",
    "\n",
    "# otsu threshold of the image\n",
    "def find_otsu_t(img):\n",
    "    t, thresh_img = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return t, thresh_img\n",
    "\n",
    "# hmax transform of the image\n",
    "def h_max_transform(img,h):\n",
    "    h_maxima = extrema.h_maxima(img, h)\n",
    "    label_h_maxima = label(h_maxima)\n",
    "    label_h_maxima[label_h_maxima>0] = 255\n",
    "    return label_h_maxima\n",
    "\n",
    "# Detect the foci of a nuclei, given the green channel\n",
    "def detect_FOCI(g):\n",
    "    # Dehaze\n",
    "    dehazed = dehaze(g)\n",
    "\n",
    "    # Adaptive median filter remove noise     \n",
    "    for i in range(7, 1, -2):\n",
    "        g = adaptive_median_filter(g,i)\n",
    "\n",
    "    # Top hat transform to detect posible foci locations    \n",
    "    top = top_hat_transform(dehazed,25)\n",
    "    \n",
    "    # Convert to int     \n",
    "    top = np.uint8(top)\n",
    "\n",
    "    # Detect Foci Regions by Threshold \n",
    "    t, mask = find_otsu_t(top)\n",
    "\n",
    "    # Get only the object by overylaying the mask\n",
    "    fig = cv2.bitwise_or(top, top, mask=mask)\n",
    "\n",
    "    # Get the extrema and label the foci  \n",
    "    labeled = h_max_transform(fig,t)\n",
    "\n",
    "    return labeled, dehazed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detemine class based on foci\n",
    "def Classify_Image(foci_image):\n",
    "    b, g, r = cv2.split(foci_image)\n",
    "    # If anything is in the blue channel then it is labeled as a foci\n",
    "    if 255 in b:\n",
    "        return \"Damaged\"\n",
    "    return \"Healthy\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T01_XY1_RGB.tif\n",
      "[INFO] 13 unique segments found\n",
      "Obtaining Features for nuclei 1\n",
      "Obtaining Features for nuclei 2\n",
      "Obtaining Features for nuclei 3\n",
      "Obtaining Features for nuclei 4\n",
      "Obtaining Features for nuclei 5\n",
      "Obtaining Features for nuclei 6\n",
      "Obtaining Features for nuclei 7\n",
      "Obtaining Features for nuclei 8\n",
      "Obtaining Features for nuclei 9\n",
      "Obtaining Features for nuclei 10\n",
      "Obtaining Features for nuclei 11\n",
      "Obtaining Features for nuclei 12\n",
      "Obtaining Features for nuclei 13\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T02_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 14\n",
      "Obtaining Features for nuclei 15\n",
      "Obtaining Features for nuclei 16\n",
      "Obtaining Features for nuclei 17\n",
      "Obtaining Features for nuclei 18\n",
      "Obtaining Features for nuclei 19\n",
      "Obtaining Features for nuclei 20\n",
      "Obtaining Features for nuclei 21\n",
      "Obtaining Features for nuclei 22\n",
      "Obtaining Features for nuclei 23\n",
      "Obtaining Features for nuclei 24\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T03_XY1_RGB.tif\n",
      "[INFO] 12 unique segments found\n",
      "Obtaining Features for nuclei 25\n",
      "Obtaining Features for nuclei 26\n",
      "Obtaining Features for nuclei 27\n",
      "Obtaining Features for nuclei 28\n",
      "Obtaining Features for nuclei 29\n",
      "Obtaining Features for nuclei 30\n",
      "Obtaining Features for nuclei 31\n",
      "Obtaining Features for nuclei 32\n",
      "Obtaining Features for nuclei 33\n",
      "Obtaining Features for nuclei 34\n",
      "Obtaining Features for nuclei 35\n",
      "Obtaining Features for nuclei 36\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T04_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 37\n",
      "Obtaining Features for nuclei 38\n",
      "Obtaining Features for nuclei 39\n",
      "Obtaining Features for nuclei 40\n",
      "Obtaining Features for nuclei 41\n",
      "Obtaining Features for nuclei 42\n",
      "Obtaining Features for nuclei 43\n",
      "Obtaining Features for nuclei 44\n",
      "Obtaining Features for nuclei 45\n",
      "Obtaining Features for nuclei 46\n",
      "Obtaining Features for nuclei 47\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T05_XY1_RGB.tif\n",
      "[INFO] 12 unique segments found\n",
      "Obtaining Features for nuclei 48\n",
      "Obtaining Features for nuclei 49\n",
      "Obtaining Features for nuclei 50\n",
      "Obtaining Features for nuclei 51\n",
      "Obtaining Features for nuclei 52\n",
      "Obtaining Features for nuclei 53\n",
      "Obtaining Features for nuclei 54\n",
      "Obtaining Features for nuclei 55\n",
      "Obtaining Features for nuclei 56\n",
      "Obtaining Features for nuclei 57\n",
      "Obtaining Features for nuclei 58\n",
      "Obtaining Features for nuclei 59\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T06_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 60\n",
      "Obtaining Features for nuclei 61\n",
      "Obtaining Features for nuclei 62\n",
      "Obtaining Features for nuclei 63\n",
      "Obtaining Features for nuclei 64\n",
      "Obtaining Features for nuclei 65\n",
      "Obtaining Features for nuclei 66\n",
      "Obtaining Features for nuclei 67\n",
      "Obtaining Features for nuclei 68\n",
      "Obtaining Features for nuclei 69\n",
      "Obtaining Features for nuclei 70\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T07_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 71\n",
      "Obtaining Features for nuclei 72\n",
      "Obtaining Features for nuclei 73\n",
      "Obtaining Features for nuclei 74\n",
      "Obtaining Features for nuclei 75\n",
      "Obtaining Features for nuclei 76\n",
      "Obtaining Features for nuclei 77\n",
      "Obtaining Features for nuclei 78\n",
      "Obtaining Features for nuclei 79\n",
      "Obtaining Features for nuclei 80\n",
      "Obtaining Features for nuclei 81\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T08_XY1_RGB.tif\n",
      "[INFO] 10 unique segments found\n",
      "Obtaining Features for nuclei 82\n",
      "Obtaining Features for nuclei 83\n",
      "Obtaining Features for nuclei 84\n",
      "Obtaining Features for nuclei 85\n",
      "Obtaining Features for nuclei 86\n",
      "Obtaining Features for nuclei 87\n",
      "Obtaining Features for nuclei 88\n",
      "Obtaining Features for nuclei 89\n",
      "Obtaining Features for nuclei 90\n",
      "Obtaining Features for nuclei 91\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T09_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 92\n",
      "Obtaining Features for nuclei 93\n",
      "Obtaining Features for nuclei 94\n",
      "Obtaining Features for nuclei 95\n",
      "Obtaining Features for nuclei 96\n",
      "Obtaining Features for nuclei 97\n",
      "Obtaining Features for nuclei 98\n",
      "Obtaining Features for nuclei 99\n",
      "Obtaining Features for nuclei 100\n",
      "Obtaining Features for nuclei 101\n",
      "Obtaining Features for nuclei 102\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T11_XY1_RGB.tif\n",
      "[INFO] 12 unique segments found\n",
      "Obtaining Features for nuclei 103\n",
      "Obtaining Features for nuclei 104\n",
      "Obtaining Features for nuclei 105\n",
      "Obtaining Features for nuclei 106\n",
      "Obtaining Features for nuclei 107\n",
      "Obtaining Features for nuclei 108\n",
      "Obtaining Features for nuclei 109\n",
      "Obtaining Features for nuclei 110\n",
      "Obtaining Features for nuclei 111\n",
      "Obtaining Features for nuclei 112\n",
      "Obtaining Features for nuclei 113\n",
      "Obtaining Features for nuclei 114\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T12_XY1_RGB.tif\n",
      "[INFO] 12 unique segments found\n",
      "Obtaining Features for nuclei 115\n",
      "Obtaining Features for nuclei 116\n",
      "Obtaining Features for nuclei 117\n",
      "Obtaining Features for nuclei 118\n",
      "Obtaining Features for nuclei 119\n",
      "Obtaining Features for nuclei 120\n",
      "Obtaining Features for nuclei 121\n",
      "Obtaining Features for nuclei 122\n",
      "Obtaining Features for nuclei 123\n",
      "Obtaining Features for nuclei 124\n",
      "Obtaining Features for nuclei 125\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T13_XY1_RGB.tif\n",
      "[INFO] 14 unique segments found\n",
      "Obtaining Features for nuclei 126\n",
      "Obtaining Features for nuclei 127\n",
      "Obtaining Features for nuclei 128\n",
      "Obtaining Features for nuclei 129\n",
      "Obtaining Features for nuclei 130\n",
      "Obtaining Features for nuclei 131\n",
      "Obtaining Features for nuclei 132\n",
      "Obtaining Features for nuclei 133\n",
      "Obtaining Features for nuclei 134\n",
      "Obtaining Features for nuclei 135\n",
      "Obtaining Features for nuclei 136\n",
      "Obtaining Features for nuclei 137\n",
      "Obtaining Features for nuclei 138\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T14_XY1_RGB.tif\n",
      "[INFO] 13 unique segments found\n",
      "Obtaining Features for nuclei 139\n",
      "Obtaining Features for nuclei 140\n",
      "Obtaining Features for nuclei 141\n",
      "Obtaining Features for nuclei 142\n",
      "Obtaining Features for nuclei 143\n",
      "Obtaining Features for nuclei 144\n",
      "Obtaining Features for nuclei 145\n",
      "Obtaining Features for nuclei 146\n",
      "Obtaining Features for nuclei 147\n",
      "Obtaining Features for nuclei 148\n",
      "Obtaining Features for nuclei 149\n",
      "Obtaining Features for nuclei 150\n",
      "Obtaining Features for nuclei 151\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T15_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 152\n",
      "Obtaining Features for nuclei 153\n",
      "Obtaining Features for nuclei 154\n",
      "Obtaining Features for nuclei 155\n",
      "Obtaining Features for nuclei 156\n",
      "Obtaining Features for nuclei 157\n",
      "Obtaining Features for nuclei 158\n",
      "Obtaining Features for nuclei 159\n",
      "Obtaining Features for nuclei 160\n",
      "Obtaining Features for nuclei 161\n",
      "Obtaining Features for nuclei 162\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T16_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 163\n",
      "Obtaining Features for nuclei 164\n",
      "Obtaining Features for nuclei 165\n",
      "Obtaining Features for nuclei 166\n",
      "Obtaining Features for nuclei 167\n",
      "Obtaining Features for nuclei 168\n",
      "Obtaining Features for nuclei 169\n",
      "Obtaining Features for nuclei 170\n",
      "Obtaining Features for nuclei 171\n",
      "Obtaining Features for nuclei 172\n",
      "Obtaining Features for nuclei 173\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T17_XY1_RGB.tif\n",
      "[INFO] 10 unique segments found\n",
      "Obtaining Features for nuclei 174\n",
      "Obtaining Features for nuclei 175\n",
      "Obtaining Features for nuclei 176\n",
      "Obtaining Features for nuclei 177\n",
      "Obtaining Features for nuclei 178\n",
      "Obtaining Features for nuclei 179\n",
      "Obtaining Features for nuclei 180\n",
      "Obtaining Features for nuclei 181\n",
      "Obtaining Features for nuclei 182\n",
      "Obtaining Features for nuclei 183\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T18_XY1_RGB.tif\n",
      "[INFO] 12 unique segments found\n",
      "Obtaining Features for nuclei 184\n",
      "Obtaining Features for nuclei 185\n",
      "Obtaining Features for nuclei 186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining Features for nuclei 187\n",
      "Obtaining Features for nuclei 188\n",
      "Obtaining Features for nuclei 189\n",
      "Obtaining Features for nuclei 190\n",
      "Obtaining Features for nuclei 191\n",
      "Obtaining Features for nuclei 192\n",
      "Obtaining Features for nuclei 193\n",
      "Obtaining Features for nuclei 194\n",
      "Obtaining Features for nuclei 195\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T19_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 196\n",
      "Obtaining Features for nuclei 197\n",
      "Obtaining Features for nuclei 198\n",
      "Obtaining Features for nuclei 199\n",
      "Obtaining Features for nuclei 200\n",
      "Obtaining Features for nuclei 201\n",
      "Obtaining Features for nuclei 202\n",
      "Obtaining Features for nuclei 203\n",
      "Obtaining Features for nuclei 204\n",
      "Obtaining Features for nuclei 205\n",
      "Obtaining Features for nuclei 206\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T20_XY1_RGB.tif\n",
      "[INFO] 11 unique segments found\n",
      "Obtaining Features for nuclei 207\n",
      "Obtaining Features for nuclei 208\n",
      "Obtaining Features for nuclei 209\n",
      "Obtaining Features for nuclei 210\n",
      "Obtaining Features for nuclei 211\n",
      "Obtaining Features for nuclei 212\n",
      "Obtaining Features for nuclei 213\n",
      "Obtaining Features for nuclei 214\n",
      "Obtaining Features for nuclei 215\n",
      "Obtaining Features for nuclei 216\n",
      "Obtaining Features for nuclei 217\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T21_XY1_RGB.tif\n",
      "[INFO] 10 unique segments found\n",
      "Obtaining Features for nuclei 218\n",
      "Obtaining Features for nuclei 219\n",
      "Obtaining Features for nuclei 220\n",
      "Obtaining Features for nuclei 221\n",
      "Obtaining Features for nuclei 222\n",
      "Obtaining Features for nuclei 223\n",
      "Obtaining Features for nuclei 224\n",
      "Obtaining Features for nuclei 225\n",
      "Obtaining Features for nuclei 226\n",
      "Obtaining Features for nuclei 227\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T22_XY1_RGB.tif\n",
      "[INFO] 10 unique segments found\n",
      "Obtaining Features for nuclei 228\n",
      "Obtaining Features for nuclei 229\n",
      "Obtaining Features for nuclei 230\n",
      "Obtaining Features for nuclei 231\n",
      "Obtaining Features for nuclei 232\n",
      "Obtaining Features for nuclei 233\n",
      "Obtaining Features for nuclei 234\n",
      "Obtaining Features for nuclei 235\n",
      "Obtaining Features for nuclei 236\n",
      "Obtaining Features for nuclei 237\n",
      "Generating Nuclei Crops for: ./Dataset/WellC3_Seq0010_WellC3_Seq0010_T23_XY1_RGB.tif\n",
      "[INFO] 10 unique segments found\n",
      "Obtaining Features for nuclei 238\n",
      "Obtaining Features for nuclei 239\n",
      "Obtaining Features for nuclei 240\n",
      "Obtaining Features for nuclei 241\n",
      "Obtaining Features for nuclei 242\n",
      "Obtaining Features for nuclei 243\n",
      "Obtaining Features for nuclei 244\n",
      "Obtaining Features for nuclei 245\n",
      "Obtaining Features for nuclei 246\n",
      "Obtaining Features for nuclei 247\n",
      "Writing to file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get Frames in the dataset\n",
    "Frames_list = os.listdir(Dataset_location)\n",
    "Frames_list.sort()\n",
    "\n",
    "# Nuclei tracker over all nuclei\n",
    "nuclei_count = 0\n",
    "\n",
    "# Report Dictionary\n",
    "classdict = {}\n",
    "\n",
    "\n",
    "# for each frame in the dataset...\n",
    "for frame in Frames_list:\n",
    "    frame_img_location = os.path.join(Dataset_location,frame)\n",
    "    print(\"Generating Nuclei Crops for: \" + frame_img_location)\n",
    "\n",
    "    # Read the image and split by channel\n",
    "    data_array = cv2.imread(frame_img_location, 1)\n",
    "    b, g, r = cv2.split(data_array)\n",
    "\n",
    "    '''\n",
    "    NOTE: \n",
    "    \n",
    "    \"labeled\" means that each nuclei is given a \n",
    "    unique identifier [1-255] and background is 0\n",
    "    \n",
    "    '''\n",
    "############### Detect FOCI #########################\n",
    "\n",
    "    # obtain the foci locations\n",
    "    foci_labeled, dehazed = detect_FOCI(g)\n",
    "\n",
    "############### Detect Nuclei #########################\n",
    "\n",
    "    # obtain the nuclei locations\n",
    "    labeled_cells,num = detect_NUCLEI(r)\n",
    "\n",
    "    \n",
    "\n",
    "    # make an image with all GFP, nuclei labels, and foci labels,\n",
    "    detected_nuclei = labeled_cells.copy()\n",
    "    detected_nuclei[detected_nuclei>0]=255\n",
    "    \n",
    "    # height, width, layers of an image\n",
    "    height, width = labeled_cells.shape\n",
    "\n",
    "    all_labels = np.zeros((height, width, 3), dtype=\"uint8\")  # matrix of zeros (black)\n",
    "    all_labels[:, :, 0] = foci_labeled\n",
    "    all_labels[:, :, 1] = dehazed\n",
    "    all_labels[:, :, 2] = detected_nuclei\n",
    "\n",
    "    # iterate through each nuclei\n",
    "    for i in num:\n",
    "                \n",
    "############### Mask Segmentation #########################\n",
    "        \n",
    "        # obtain a mask of the nuclei\n",
    "        mask = np.where(labeled_cells == i, 255, 0)\n",
    "    \n",
    "        '''\n",
    "        crop the individual cell\n",
    "        given a mask and the OG image, \n",
    "        overlay mask onto the OG image \n",
    "        and return the cropped segmented object\n",
    "        '''\n",
    "       \n",
    "        # convert into unsigned int\n",
    "        mask = np.uint8(mask)\n",
    "\n",
    "        # overlay mask with the original image\n",
    "        single_nuclei = cv2.bitwise_and(r, r, mask=mask)\n",
    "\n",
    "        # obtain contours of the nuclei\n",
    "        contours, hierarchy = cv2.findContours(single_nuclei, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if not len(contours) == 0:\n",
    "            # obtain max contour area\n",
    "            cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # calc bounding box\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            # Crop the 3 layer channels\n",
    "            single_nuclei_foci = cv2.bitwise_and(all_labels[:, :, 0], all_labels[:, :, 0], mask=mask)\n",
    "            single_nuclei_green_channel = cv2.bitwise_and(all_labels[:, :, 1], all_labels[:, :, 1], mask=mask)\n",
    "\n",
    "            segmented = np.zeros((height, width, 3), dtype=\"uint8\")  # matrix of zeros (black)\n",
    "\n",
    "            # make overlay into 3 channels (bgr)\n",
    "            segmented[:, :, 0] = single_nuclei_foci\n",
    "            segmented[:, :, 1] = single_nuclei_green_channel\n",
    "            segmented[:, :, 2] = single_nuclei\n",
    "\n",
    "            # crop the image based on bounding box\n",
    "            crop_img = segmented[y - 1:y + h + 1, x - 1:x + w + 1]\n",
    "            mask = mask[y - 1:y + h + 1, x - 1:x + w + 1]\n",
    "            crop_img = cv2.bitwise_and(crop_img, crop_img, mask=mask)\n",
    "\n",
    "            # Increment nuclei count            \n",
    "            nuclei_count = nuclei_count+1\n",
    "            \n",
    "            \n",
    "            \n",
    "############### Normalize Nuclei #########################\n",
    "           \n",
    "            # Get just the red channel         \n",
    "            single_nuclei = crop_img[:,:,2]\n",
    "    \n",
    "            # Obtain Axis Features         \n",
    "            x, y, minor, major, maj_angle, min_angle, ecc = get_axis(cnt)\n",
    "            \n",
    "            # Rotate the nuclei             \n",
    "            rot_single_nuclei = rotate_bound(single_nuclei, -maj_angle)\n",
    "            \n",
    "            # Pad inamge to 200x200            \n",
    "            rot_single_nuclei = padImage(rot_single_nuclei, 150, 150)\n",
    "\n",
    "            # Write nuclei to file             \n",
    "            crop_loc = \"./Crops/\" + str(nuclei_count) + \".tif\"\n",
    "            cv2.imwrite(crop_loc, rot_single_nuclei)\n",
    "            \n",
    "            # Upscale image       \n",
    "            rot_single_nuclei = bilinear_upscale(rot_single_nuclei,rate=2)\n",
    "            cv2.imwrite(crop_loc, rot_single_nuclei)\n",
    "\n",
    "            ############### Feature Extraction #########################\n",
    "\n",
    "            print(\"Obtaining Features for nuclei \" + str(nuclei_count))\n",
    "\n",
    "            classification = Classify_Image(crop_img)\n",
    "            asp = fd_aspect_ratio(cnt)\n",
    "            ext = fd_extent(cnt)\n",
    "            sold = fd_solidity(cnt)\n",
    "            diam = fd_Equi_diameter(cnt)\n",
    "            roundness_feature = fd_roundness(cnt)\n",
    "            zern = fd_Zern(rot_single_nuclei, int(math.floor(diam/2)))\n",
    "            har = fd_haralick(rot_single_nuclei)\n",
    "            hu = fd_hu_moments(rot_single_nuclei)\n",
    "            linear_hist = fd_linearbinarypattern(rot_single_nuclei)\n",
    "            fd = fd_HOG(rot_single_nuclei)\n",
    "#             You need to do some special installation for SIFT\n",
    "#             des = fd_SIFT(rot_single_nuclei)\n",
    "            log = fd_LoG(rot_single_nuclei)\n",
    "            Gabor = fd_GaborWavelet(rot_single_nuclei)\n",
    "            \n",
    "############### Write to file #########################\n",
    "\n",
    "\n",
    "            classdict[crop_loc] = {}\n",
    "            \n",
    "            # 1D descriptors           \n",
    "            classdict[crop_loc][\"Original Frame\"] = frame_img_location\n",
    "            classdict[crop_loc][\"Cropped Frame\"] = crop_loc\n",
    "            classdict[crop_loc][\"True Classification\"] = classification\n",
    "            classdict[crop_loc][\"Centroid_x\"] = x\n",
    "            classdict[crop_loc][\"Centroid_y\"] = y\n",
    "            classdict[crop_loc][\"Major Axis\"] = major\n",
    "            classdict[crop_loc][\"Minor Axis\"] = minor\n",
    "            classdict[crop_loc][\"Eccentricity\"] = ecc\n",
    "            classdict[crop_loc][\"Aspect Ratio\"] = asp\n",
    "            classdict[crop_loc][\"Solidity\"] = sold\n",
    "            classdict[crop_loc][\"Equivalent Diameter\"] = diam\n",
    "            classdict[crop_loc][\"Roundness\"] = roundness_feature\n",
    "            classdict[crop_loc][\"Extent\"] = ext\n",
    "            \n",
    "            # 2D descriptors             \n",
    "            \n",
    "            StoreNDArray(classdict[crop_loc], \"Zernlike Moments\", zern)\n",
    " \n",
    "            StoreHaralickFeature(classdict[crop_loc],har)\n",
    "\n",
    "            # classdict[crop_loc][\"Hu Moments\"] = hu\n",
    "            StoreNDArray(classdict[crop_loc], \"Hu Moments\", hu)\n",
    "            \n",
    "            StoreNDArray(classdict[crop_loc], \"Linear Binary Patterns\", linear_hist)\n",
    "\n",
    "            \n",
    "            HOG_loc = \"./HOG/\" + str(nuclei_count)+\".tif\"\n",
    "            cv2.imwrite(HOG_loc, fd)\n",
    "            classdict[crop_loc][\"HOG\"] = HOG_loc\n",
    "\n",
    "#             StoreNDArray(classdict[crop_loc], \"SIFT\", des)\n",
    "\n",
    "            LOG_loc = \"./LOG/\" + str(nuclei_count) + \".tif\"\n",
    "            cv2.imwrite(LOG_loc, log)\n",
    "            classdict[crop_loc][\"Laplace of Gaussian\"] = LOG_loc\n",
    "\n",
    "            Gabor_loc = \"./Gabor/\" + str(nuclei_count) + \".tif\"\n",
    "            cv2.imwrite(Gabor_loc,Gabor)\n",
    "            classdict[crop_loc][\"Gabor Wavelet\"] = Gabor_loc\n",
    "            \n",
    "        \n",
    "print(\"Writing to file...\")        \n",
    "dataframe = pd.DataFrame.from_dict(classdict).T\n",
    "dataframe.to_csv('dataset_report.csv', index=False)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sum varience', 'Roundness', 'Linear Binary Patterns180', 'Linear Binary Patterns169', 'Linear Binary Patterns166', 'Linear Binary Patterns74', 'Linear Binary Patterns73', 'Linear Binary Patterns208', 'Linear Binary Patterns15', 'sum of squares: varience']\n",
      "['sum varience', 'Solidity', 'Roundness', 'Zernlike Moments4', 'Extent', 'Zernlike Moments11', 'Linear Binary Patterns180', 'Linear Binary Patterns169', 'Linear Binary Patterns166', 'Linear Binary Patterns15']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./dataset_report.csv\")\n",
    "\n",
    "meta_headers = ['Cropped Frame','Original Frame', \"HOG\",\"Laplace of Gaussian\",\"Gabor Wavelet\",\"Centroid_x\",\"Centroid_y\"]\n",
    "meta_data = dataset.filter(meta_headers, axis=1)\n",
    "\n",
    "# Mix and matrch what features are important by removing specific features\n",
    "# SIFT = dataset.filter(regex=(\"SIFT.*\"))\n",
    "# LBP = dataset.filter(regex=(\"Linear Binary Patterns.*\"))\n",
    "# dataset.drop(SIFT, axis=1, inplace=True)\n",
    "# dataset.drop(LBP, axis=1, inplace=True)\n",
    "# ZLM = dataset.filter(regex=(\"Zernlike Moments.*\"))\n",
    "# dataset.drop(ZLM, axis=1, inplace=True)\n",
    "\n",
    "dataset.drop(meta_headers, axis=1, inplace=True)\n",
    "dataset.drop(labels=['True Classification'], axis=1,inplace = True)\n",
    "\n",
    "dataset= dataset.replace(\"Healthy\",-1)\n",
    "dataset = dataset.replace(\"Damaged\",1)\n",
    "\n",
    "dataset.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "# Print top features based on selection metrics\n",
    "print(pymrmr.mRMR(dataset, 'MIQ',10))\n",
    "print(pymrmr.mRMR(dataset, 'MID',10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Play around with the features you want to use and which ones have better classification power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMetrics(confusion_matrix):\n",
    "    TP = confusion_matrix[0,0]\n",
    "    FP = confusion_matrix[0,1]\n",
    "    FN = confusion_matrix[1,0]\n",
    "    TN = confusion_matrix[1,1]\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "\n",
    "    if TP == 0:\n",
    "        fscore = 0\n",
    "    else:\n",
    "        fscore = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "    # false negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "\n",
    "    # false positive rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # specificity\n",
    "    SPC = TN/(FN+TN)\n",
    "\n",
    "    # accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "    return fscore,FNR,FDR,SPC,ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4]\n",
      " [ 0 18]]\n",
      "[[ 5  0]\n",
      " [ 0 20]]\n",
      "[[ 2  3]\n",
      " [ 0 20]]\n",
      "[[ 4  0]\n",
      " [ 0 21]]\n",
      "[[ 2  2]\n",
      " [ 0 21]]\n",
      "[[ 3  0]\n",
      " [ 1 21]]\n",
      "[[ 3  1]\n",
      " [ 1 20]]\n",
      "[[ 1  1]\n",
      " [ 0 22]]\n",
      "[[ 1  0]\n",
      " [ 2 21]]\n",
      "[[ 4  1]\n",
      " [ 0 19]]\n",
      "Average F-score: 0.7500793650793651\n",
      "Average Accuracy: 0.9353333333333333\n",
      "Average False Negative Rate: 0.11666666666666665\n",
      "Average Specificity: 0.9819969885187276\n",
      "Average False Discovery Rate: 0.2621428571428571\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv(\"./dataset_report.csv\")\n",
    "\n",
    "\n",
    "meta_headers = ['Cropped Frame','Original Frame', \"HOG\",\"Laplace of Gaussian\",\"Gabor Wavelet\",\"Centroid_x\",\"Centroid_y\"]\n",
    "\n",
    "meta_data = dataset.filter(meta_headers, axis=1)\n",
    "dataset.drop(meta_headers, axis=1, inplace=True)\n",
    "\n",
    "dataset= dataset.replace(\"Healthy\",1)\n",
    "dataset = dataset.replace(\"Damaged\",0)\n",
    "\n",
    "dataset = dataset.fillna(0)\n",
    "\n",
    "\n",
    "# move classes to first column\n",
    "mid = dataset['True Classification']\n",
    "# print(mid)\n",
    "dataset.drop(labels=['True Classification'], axis=1,inplace = True)\n",
    "\n",
    "head = np.array(dataset.columns.values)\n",
    "\n",
    "dataset.insert(0, 'True Classification', mid)\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "# Shuffle the data so that the K folds are not to be influenced by the original frame\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "X = dataset[:, 1:]\n",
    "y = dataset[:, 0]\n",
    "\n",
    "max_features = min(X.shape[1],X.shape[0])\n",
    "splits=10\n",
    "kf = KFold(n_splits=splits)\n",
    "accuracy_sum = 0\n",
    "fscore_sum = 0\n",
    "FNR_sum = 0\n",
    "FDR_sum = 0\n",
    "SPC_sum = 0\n",
    "\n",
    "for train, test in kf.split(dataset):\n",
    "    X_train = dataset[train][:,1:]\n",
    "    y_train = dataset[train][:,0]\n",
    "\n",
    "    X_test = dataset[test][:,1:]\n",
    "    y_test = dataset[test][:,0]\n",
    "\n",
    "\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "\n",
    "    regressor = RandomForestClassifier(n_estimators=100, random_state=2, max_depth=10, criterion='gini',max_features=max_features)\n",
    "    regressor.fit(X_train, training_scores_encoded)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    # appendDFToCSV_void(importances.T, report_location,head)\n",
    "\n",
    "    cn_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(cn_matrix)\n",
    "    fscore, FNR, FDR, SPC, ACC = calcMetrics(cn_matrix)\n",
    "\n",
    "    accuracy_sum = accuracy_sum + ACC\n",
    "    fscore_sum = fscore_sum + fscore\n",
    "    FNR_sum = FNR_sum + FNR\n",
    "    FDR_sum = FDR_sum + FDR\n",
    "    SPC_sum = SPC_sum + SPC\n",
    "\n",
    "\n",
    "accuracy_average = accuracy_sum/splits\n",
    "fscore_avg = fscore_sum/splits\n",
    "FNR_avg = FNR_sum/splits\n",
    "FDR_avg = FDR_sum/splits\n",
    "SPC_avg = SPC_sum/splits\n",
    "\n",
    "print(\"Average F-score: \" + str(fscore_avg))\n",
    "print(\"Average Accuracy: \" + str(accuracy_average))\n",
    "print(\"Average False Negative Rate: \" + str(FNR_avg))\n",
    "print(\"Average Specificity: \" + str(SPC_avg))\n",
    "print(\"Average False Discovery Rate: \" + str(FDR_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Crops/1.tif' './Crops/2.tif' './Crops/3.tif' './Crops/4.tif'\n",
      " './Crops/5.tif' './Crops/6.tif' './Crops/7.tif' './Crops/8.tif'\n",
      " './Crops/9.tif' './Crops/10.tif' './Crops/11.tif' './Crops/12.tif'\n",
      " './Crops/13.tif' './Crops/14.tif' './Crops/15.tif' './Crops/16.tif'\n",
      " './Crops/17.tif' './Crops/18.tif' './Crops/19.tif' './Crops/20.tif'\n",
      " './Crops/21.tif' './Crops/22.tif' './Crops/23.tif' './Crops/24.tif'\n",
      " './Crops/25.tif' './Crops/26.tif' './Crops/27.tif' './Crops/28.tif'\n",
      " './Crops/29.tif' './Crops/30.tif' './Crops/31.tif' './Crops/32.tif'\n",
      " './Crops/33.tif' './Crops/34.tif' './Crops/35.tif' './Crops/36.tif'\n",
      " './Crops/37.tif' './Crops/38.tif' './Crops/39.tif' './Crops/40.tif'\n",
      " './Crops/41.tif' './Crops/42.tif' './Crops/43.tif' './Crops/44.tif'\n",
      " './Crops/45.tif' './Crops/46.tif' './Crops/47.tif' './Crops/48.tif'\n",
      " './Crops/49.tif' './Crops/50.tif' './Crops/51.tif' './Crops/52.tif'\n",
      " './Crops/53.tif' './Crops/54.tif' './Crops/55.tif' './Crops/56.tif'\n",
      " './Crops/57.tif' './Crops/58.tif' './Crops/59.tif' './Crops/60.tif'\n",
      " './Crops/61.tif' './Crops/62.tif' './Crops/63.tif' './Crops/64.tif'\n",
      " './Crops/65.tif' './Crops/66.tif' './Crops/67.tif' './Crops/68.tif'\n",
      " './Crops/69.tif' './Crops/70.tif' './Crops/71.tif' './Crops/72.tif'\n",
      " './Crops/73.tif' './Crops/74.tif' './Crops/75.tif' './Crops/76.tif'\n",
      " './Crops/77.tif' './Crops/78.tif' './Crops/79.tif' './Crops/80.tif'\n",
      " './Crops/81.tif' './Crops/82.tif' './Crops/83.tif' './Crops/84.tif'\n",
      " './Crops/85.tif' './Crops/86.tif' './Crops/87.tif' './Crops/88.tif'\n",
      " './Crops/89.tif' './Crops/90.tif' './Crops/91.tif' './Crops/92.tif'\n",
      " './Crops/93.tif' './Crops/94.tif' './Crops/95.tif' './Crops/96.tif'\n",
      " './Crops/97.tif' './Crops/98.tif' './Crops/99.tif' './Crops/100.tif'\n",
      " './Crops/101.tif' './Crops/102.tif' './Crops/103.tif' './Crops/104.tif'\n",
      " './Crops/105.tif' './Crops/106.tif' './Crops/107.tif' './Crops/108.tif'\n",
      " './Crops/109.tif' './Crops/110.tif' './Crops/111.tif' './Crops/112.tif'\n",
      " './Crops/113.tif' './Crops/114.tif' './Crops/115.tif' './Crops/116.tif'\n",
      " './Crops/117.tif' './Crops/118.tif' './Crops/119.tif' './Crops/120.tif'\n",
      " './Crops/121.tif' './Crops/122.tif' './Crops/123.tif' './Crops/124.tif'\n",
      " './Crops/125.tif' './Crops/126.tif' './Crops/127.tif' './Crops/128.tif'\n",
      " './Crops/129.tif' './Crops/130.tif' './Crops/131.tif' './Crops/132.tif'\n",
      " './Crops/133.tif' './Crops/134.tif' './Crops/135.tif' './Crops/136.tif'\n",
      " './Crops/137.tif' './Crops/138.tif' './Crops/139.tif' './Crops/140.tif'\n",
      " './Crops/141.tif' './Crops/142.tif' './Crops/143.tif' './Crops/144.tif'\n",
      " './Crops/145.tif' './Crops/146.tif' './Crops/147.tif' './Crops/148.tif'\n",
      " './Crops/149.tif' './Crops/150.tif' './Crops/151.tif' './Crops/152.tif'\n",
      " './Crops/153.tif' './Crops/154.tif' './Crops/155.tif' './Crops/156.tif'\n",
      " './Crops/157.tif' './Crops/158.tif' './Crops/159.tif' './Crops/160.tif'\n",
      " './Crops/161.tif' './Crops/162.tif' './Crops/163.tif' './Crops/164.tif'\n",
      " './Crops/165.tif' './Crops/166.tif' './Crops/167.tif' './Crops/168.tif'\n",
      " './Crops/169.tif' './Crops/170.tif' './Crops/171.tif' './Crops/172.tif'\n",
      " './Crops/173.tif' './Crops/174.tif' './Crops/175.tif' './Crops/176.tif'\n",
      " './Crops/177.tif' './Crops/178.tif' './Crops/179.tif' './Crops/180.tif'\n",
      " './Crops/181.tif' './Crops/182.tif' './Crops/183.tif' './Crops/184.tif'\n",
      " './Crops/185.tif' './Crops/186.tif' './Crops/187.tif' './Crops/188.tif'\n",
      " './Crops/189.tif' './Crops/190.tif' './Crops/191.tif' './Crops/192.tif'\n",
      " './Crops/193.tif' './Crops/194.tif' './Crops/195.tif' './Crops/196.tif'\n",
      " './Crops/197.tif' './Crops/198.tif' './Crops/199.tif' './Crops/200.tif'\n",
      " './Crops/201.tif' './Crops/202.tif' './Crops/203.tif' './Crops/204.tif'\n",
      " './Crops/205.tif' './Crops/206.tif' './Crops/207.tif' './Crops/208.tif'\n",
      " './Crops/209.tif' './Crops/210.tif' './Crops/211.tif' './Crops/212.tif'\n",
      " './Crops/213.tif' './Crops/214.tif' './Crops/215.tif' './Crops/216.tif'\n",
      " './Crops/217.tif' './Crops/218.tif' './Crops/219.tif' './Crops/220.tif'\n",
      " './Crops/221.tif' './Crops/222.tif' './Crops/223.tif' './Crops/224.tif'\n",
      " './Crops/225.tif' './Crops/226.tif' './Crops/227.tif' './Crops/228.tif'\n",
      " './Crops/229.tif' './Crops/230.tif' './Crops/231.tif' './Crops/232.tif'\n",
      " './Crops/233.tif' './Crops/234.tif' './Crops/235.tif' './Crops/236.tif'\n",
      " './Crops/237.tif' './Crops/238.tif' './Crops/239.tif' './Crops/240.tif'\n",
      " './Crops/241.tif' './Crops/242.tif' './Crops/243.tif' './Crops/244.tif'\n",
      " './Crops/245.tif' './Crops/246.tif' './Crops/247.tif']\n",
      "./Crops/1.tif\n",
      "./Crops/2.tif\n",
      "./Crops/3.tif\n",
      "./Crops/4.tif\n",
      "./Crops/5.tif\n",
      "./Crops/6.tif\n",
      "./Crops/7.tif\n",
      "./Crops/8.tif\n",
      "./Crops/9.tif\n",
      "./Crops/10.tif\n",
      "./Crops/11.tif\n",
      "./Crops/12.tif\n",
      "./Crops/13.tif\n",
      "./Crops/14.tif\n",
      "./Crops/15.tif\n",
      "./Crops/16.tif\n",
      "./Crops/17.tif\n",
      "./Crops/18.tif\n",
      "./Crops/19.tif\n",
      "./Crops/20.tif\n",
      "./Crops/21.tif\n",
      "./Crops/22.tif\n",
      "./Crops/23.tif\n",
      "./Crops/24.tif\n",
      "./Crops/25.tif\n",
      "./Crops/26.tif\n",
      "./Crops/27.tif\n",
      "./Crops/28.tif\n",
      "./Crops/29.tif\n",
      "./Crops/30.tif\n",
      "./Crops/31.tif\n",
      "./Crops/32.tif\n",
      "./Crops/33.tif\n",
      "./Crops/34.tif\n",
      "./Crops/35.tif\n",
      "./Crops/36.tif\n",
      "./Crops/37.tif\n",
      "./Crops/38.tif\n",
      "./Crops/39.tif\n",
      "./Crops/40.tif\n",
      "./Crops/41.tif\n",
      "./Crops/42.tif\n",
      "./Crops/43.tif\n",
      "./Crops/44.tif\n",
      "./Crops/45.tif\n",
      "./Crops/46.tif\n",
      "./Crops/47.tif\n",
      "./Crops/48.tif\n",
      "./Crops/49.tif\n",
      "./Crops/50.tif\n",
      "./Crops/51.tif\n",
      "./Crops/52.tif\n",
      "./Crops/53.tif\n",
      "./Crops/54.tif\n",
      "./Crops/55.tif\n",
      "./Crops/56.tif\n",
      "./Crops/57.tif\n",
      "./Crops/58.tif\n",
      "./Crops/59.tif\n",
      "./Crops/60.tif\n",
      "./Crops/61.tif\n",
      "./Crops/62.tif\n",
      "./Crops/63.tif\n",
      "./Crops/64.tif\n",
      "./Crops/65.tif\n",
      "./Crops/66.tif\n",
      "./Crops/67.tif\n",
      "./Crops/68.tif\n",
      "./Crops/69.tif\n",
      "./Crops/70.tif\n",
      "./Crops/71.tif\n",
      "./Crops/72.tif\n",
      "./Crops/73.tif\n",
      "./Crops/74.tif\n",
      "./Crops/75.tif\n",
      "./Crops/76.tif\n",
      "./Crops/77.tif\n",
      "./Crops/78.tif\n",
      "./Crops/79.tif\n",
      "./Crops/80.tif\n",
      "./Crops/81.tif\n",
      "./Crops/82.tif\n",
      "./Crops/83.tif\n",
      "./Crops/84.tif\n",
      "./Crops/85.tif\n",
      "./Crops/86.tif\n",
      "./Crops/87.tif\n",
      "./Crops/88.tif\n",
      "./Crops/89.tif\n",
      "./Crops/90.tif\n",
      "./Crops/91.tif\n",
      "./Crops/92.tif\n",
      "./Crops/93.tif\n",
      "./Crops/94.tif\n",
      "./Crops/95.tif\n",
      "./Crops/96.tif\n",
      "./Crops/97.tif\n",
      "./Crops/98.tif\n",
      "./Crops/99.tif\n",
      "./Crops/100.tif\n",
      "./Crops/101.tif\n",
      "./Crops/102.tif\n",
      "./Crops/103.tif\n",
      "./Crops/104.tif\n",
      "./Crops/105.tif\n",
      "./Crops/106.tif\n",
      "./Crops/107.tif\n",
      "./Crops/108.tif\n",
      "./Crops/109.tif\n",
      "./Crops/110.tif\n",
      "./Crops/111.tif\n",
      "./Crops/112.tif\n",
      "./Crops/113.tif\n",
      "./Crops/114.tif\n",
      "./Crops/115.tif\n",
      "./Crops/116.tif\n",
      "./Crops/117.tif\n",
      "./Crops/118.tif\n",
      "./Crops/119.tif\n",
      "./Crops/120.tif\n",
      "./Crops/121.tif\n",
      "./Crops/122.tif\n",
      "./Crops/123.tif\n",
      "./Crops/124.tif\n",
      "./Crops/125.tif\n",
      "./Crops/126.tif\n",
      "./Crops/127.tif\n",
      "./Crops/128.tif\n",
      "./Crops/129.tif\n",
      "./Crops/130.tif\n",
      "./Crops/131.tif\n",
      "./Crops/132.tif\n",
      "./Crops/133.tif\n",
      "./Crops/134.tif\n",
      "./Crops/135.tif\n",
      "./Crops/136.tif\n",
      "./Crops/137.tif\n",
      "./Crops/138.tif\n",
      "./Crops/139.tif\n",
      "./Crops/140.tif\n",
      "./Crops/141.tif\n",
      "./Crops/142.tif\n",
      "./Crops/143.tif\n",
      "./Crops/144.tif\n",
      "./Crops/145.tif\n",
      "./Crops/146.tif\n",
      "./Crops/147.tif\n",
      "./Crops/148.tif\n",
      "./Crops/149.tif\n",
      "./Crops/150.tif\n",
      "./Crops/151.tif\n",
      "./Crops/152.tif\n",
      "./Crops/153.tif\n",
      "./Crops/154.tif\n",
      "./Crops/155.tif\n",
      "./Crops/156.tif\n",
      "./Crops/157.tif\n",
      "./Crops/158.tif\n",
      "./Crops/159.tif\n",
      "./Crops/160.tif\n",
      "./Crops/161.tif\n",
      "./Crops/162.tif\n",
      "./Crops/163.tif\n",
      "./Crops/164.tif\n",
      "./Crops/165.tif\n",
      "./Crops/166.tif\n",
      "./Crops/167.tif\n",
      "./Crops/168.tif\n",
      "./Crops/169.tif\n",
      "./Crops/170.tif\n",
      "./Crops/171.tif\n",
      "./Crops/172.tif\n",
      "./Crops/173.tif\n",
      "./Crops/174.tif\n",
      "./Crops/175.tif\n",
      "./Crops/176.tif\n",
      "./Crops/177.tif\n",
      "./Crops/178.tif\n",
      "./Crops/179.tif\n",
      "./Crops/180.tif\n",
      "./Crops/181.tif\n",
      "./Crops/182.tif\n",
      "./Crops/183.tif\n",
      "./Crops/184.tif\n",
      "./Crops/185.tif\n",
      "./Crops/186.tif\n",
      "./Crops/187.tif\n",
      "./Crops/188.tif\n",
      "./Crops/189.tif\n",
      "./Crops/190.tif\n",
      "./Crops/191.tif\n",
      "./Crops/192.tif\n",
      "./Crops/193.tif\n",
      "./Crops/194.tif\n",
      "./Crops/195.tif\n",
      "./Crops/196.tif\n",
      "./Crops/197.tif\n",
      "./Crops/198.tif\n",
      "./Crops/199.tif\n",
      "./Crops/200.tif\n",
      "./Crops/201.tif\n",
      "./Crops/202.tif\n",
      "./Crops/203.tif\n",
      "./Crops/204.tif\n",
      "./Crops/205.tif\n",
      "./Crops/206.tif\n",
      "./Crops/207.tif\n",
      "./Crops/208.tif\n",
      "./Crops/209.tif\n",
      "./Crops/210.tif\n",
      "./Crops/211.tif\n",
      "./Crops/212.tif\n",
      "./Crops/213.tif\n",
      "./Crops/214.tif\n",
      "./Crops/215.tif\n",
      "./Crops/216.tif\n",
      "./Crops/217.tif\n",
      "./Crops/218.tif\n",
      "./Crops/219.tif\n",
      "./Crops/220.tif\n",
      "./Crops/221.tif\n",
      "./Crops/222.tif\n",
      "./Crops/223.tif\n",
      "./Crops/224.tif\n",
      "./Crops/225.tif\n",
      "./Crops/226.tif\n",
      "./Crops/227.tif\n",
      "./Crops/228.tif\n",
      "./Crops/229.tif\n",
      "./Crops/230.tif\n",
      "./Crops/231.tif\n",
      "./Crops/232.tif\n",
      "./Crops/233.tif\n",
      "./Crops/234.tif\n",
      "./Crops/235.tif\n",
      "./Crops/236.tif\n",
      "./Crops/237.tif\n",
      "./Crops/238.tif\n",
      "./Crops/239.tif\n",
      "./Crops/240.tif\n",
      "./Crops/241.tif\n",
      "./Crops/242.tif\n",
      "./Crops/243.tif\n",
      "./Crops/244.tif\n",
      "./Crops/245.tif\n",
      "./Crops/246.tif\n",
      "./Crops/247.tif\n",
      "./HOG/1.tif\n",
      "./HOG/2.tif\n",
      "./HOG/3.tif\n",
      "./HOG/4.tif\n",
      "./HOG/5.tif\n",
      "./HOG/6.tif\n",
      "./HOG/7.tif\n",
      "./HOG/8.tif\n",
      "./HOG/9.tif\n",
      "./HOG/10.tif\n",
      "./HOG/11.tif\n",
      "./HOG/12.tif\n",
      "./HOG/13.tif\n",
      "./HOG/14.tif\n",
      "./HOG/15.tif\n",
      "./HOG/16.tif\n",
      "./HOG/17.tif\n",
      "./HOG/18.tif\n",
      "./HOG/19.tif\n",
      "./HOG/20.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./HOG/21.tif\n",
      "./HOG/22.tif\n",
      "./HOG/23.tif\n",
      "./HOG/24.tif\n",
      "./HOG/25.tif\n",
      "./HOG/26.tif\n",
      "./HOG/27.tif\n",
      "./HOG/28.tif\n",
      "./HOG/29.tif\n",
      "./HOG/30.tif\n",
      "./HOG/31.tif\n",
      "./HOG/32.tif\n",
      "./HOG/33.tif\n",
      "./HOG/34.tif\n",
      "./HOG/35.tif\n",
      "./HOG/36.tif\n",
      "./HOG/37.tif\n",
      "./HOG/38.tif\n",
      "./HOG/39.tif\n",
      "./HOG/40.tif\n",
      "./HOG/41.tif\n",
      "./HOG/42.tif\n",
      "./HOG/43.tif\n",
      "./HOG/44.tif\n",
      "./HOG/45.tif\n",
      "./HOG/46.tif\n",
      "./HOG/47.tif\n",
      "./HOG/48.tif\n",
      "./HOG/49.tif\n",
      "./HOG/50.tif\n",
      "./HOG/51.tif\n",
      "./HOG/52.tif\n",
      "./HOG/53.tif\n",
      "./HOG/54.tif\n",
      "./HOG/55.tif\n",
      "./HOG/56.tif\n",
      "./HOG/57.tif\n",
      "./HOG/58.tif\n",
      "./HOG/59.tif\n",
      "./HOG/60.tif\n",
      "./HOG/61.tif\n",
      "./HOG/62.tif\n",
      "./HOG/63.tif\n",
      "./HOG/64.tif\n",
      "./HOG/65.tif\n",
      "./HOG/66.tif\n",
      "./HOG/67.tif\n",
      "./HOG/68.tif\n",
      "./HOG/69.tif\n",
      "./HOG/70.tif\n",
      "./HOG/71.tif\n",
      "./HOG/72.tif\n",
      "./HOG/73.tif\n",
      "./HOG/74.tif\n",
      "./HOG/75.tif\n",
      "./HOG/76.tif\n",
      "./HOG/77.tif\n",
      "./HOG/78.tif\n",
      "./HOG/79.tif\n",
      "./HOG/80.tif\n",
      "./HOG/81.tif\n",
      "./HOG/82.tif\n",
      "./HOG/83.tif\n",
      "./HOG/84.tif\n",
      "./HOG/85.tif\n",
      "./HOG/86.tif\n",
      "./HOG/87.tif\n",
      "./HOG/88.tif\n",
      "./HOG/89.tif\n",
      "./HOG/90.tif\n",
      "./HOG/91.tif\n",
      "./HOG/92.tif\n",
      "./HOG/93.tif\n",
      "./HOG/94.tif\n",
      "./HOG/95.tif\n",
      "./HOG/96.tif\n",
      "./HOG/97.tif\n",
      "./HOG/98.tif\n",
      "./HOG/99.tif\n",
      "./HOG/100.tif\n",
      "./HOG/101.tif\n",
      "./HOG/102.tif\n",
      "./HOG/103.tif\n",
      "./HOG/104.tif\n",
      "./HOG/105.tif\n",
      "./HOG/106.tif\n",
      "./HOG/107.tif\n",
      "./HOG/108.tif\n",
      "./HOG/109.tif\n",
      "./HOG/110.tif\n",
      "./HOG/111.tif\n",
      "./HOG/112.tif\n",
      "./HOG/113.tif\n",
      "./HOG/114.tif\n",
      "./HOG/115.tif\n",
      "./HOG/116.tif\n",
      "./HOG/117.tif\n",
      "./HOG/118.tif\n",
      "./HOG/119.tif\n",
      "./HOG/120.tif\n",
      "./HOG/121.tif\n",
      "./HOG/122.tif\n",
      "./HOG/123.tif\n",
      "./HOG/124.tif\n",
      "./HOG/125.tif\n",
      "./HOG/126.tif\n",
      "./HOG/127.tif\n",
      "./HOG/128.tif\n",
      "./HOG/129.tif\n",
      "./HOG/130.tif\n",
      "./HOG/131.tif\n",
      "./HOG/132.tif\n",
      "./HOG/133.tif\n",
      "./HOG/134.tif\n",
      "./HOG/135.tif\n",
      "./HOG/136.tif\n",
      "./HOG/137.tif\n",
      "./HOG/138.tif\n",
      "./HOG/139.tif\n",
      "./HOG/140.tif\n",
      "./HOG/141.tif\n",
      "./HOG/142.tif\n",
      "./HOG/143.tif\n",
      "./HOG/144.tif\n",
      "./HOG/145.tif\n",
      "./HOG/146.tif\n",
      "./HOG/147.tif\n",
      "./HOG/148.tif\n",
      "./HOG/149.tif\n",
      "./HOG/150.tif\n",
      "./HOG/151.tif\n",
      "./HOG/152.tif\n",
      "./HOG/153.tif\n",
      "./HOG/154.tif\n",
      "./HOG/155.tif\n",
      "./HOG/156.tif\n",
      "./HOG/157.tif\n",
      "./HOG/158.tif\n",
      "./HOG/159.tif\n",
      "./HOG/160.tif\n",
      "./HOG/161.tif\n",
      "./HOG/162.tif\n",
      "./HOG/163.tif\n",
      "./HOG/164.tif\n",
      "./HOG/165.tif\n",
      "./HOG/166.tif\n",
      "./HOG/167.tif\n",
      "./HOG/168.tif\n",
      "./HOG/169.tif\n",
      "./HOG/170.tif\n",
      "./HOG/171.tif\n",
      "./HOG/172.tif\n",
      "./HOG/173.tif\n",
      "./HOG/174.tif\n",
      "./HOG/175.tif\n",
      "./HOG/176.tif\n",
      "./HOG/177.tif\n",
      "./HOG/178.tif\n",
      "./HOG/179.tif\n",
      "./HOG/180.tif\n",
      "./HOG/181.tif\n",
      "./HOG/182.tif\n",
      "./HOG/183.tif\n",
      "./HOG/184.tif\n",
      "./HOG/185.tif\n",
      "./HOG/186.tif\n",
      "./HOG/187.tif\n",
      "./HOG/188.tif\n",
      "./HOG/189.tif\n",
      "./HOG/190.tif\n",
      "./HOG/191.tif\n",
      "./HOG/192.tif\n",
      "./HOG/193.tif\n",
      "./HOG/194.tif\n",
      "./HOG/195.tif\n",
      "./HOG/196.tif\n",
      "./HOG/197.tif\n",
      "./HOG/198.tif\n",
      "./HOG/199.tif\n",
      "./HOG/200.tif\n",
      "./HOG/201.tif\n",
      "./HOG/202.tif\n",
      "./HOG/203.tif\n",
      "./HOG/204.tif\n",
      "./HOG/205.tif\n",
      "./HOG/206.tif\n",
      "./HOG/207.tif\n",
      "./HOG/208.tif\n",
      "./HOG/209.tif\n",
      "./HOG/210.tif\n",
      "./HOG/211.tif\n",
      "./HOG/212.tif\n",
      "./HOG/213.tif\n",
      "./HOG/214.tif\n",
      "./HOG/215.tif\n",
      "./HOG/216.tif\n",
      "./HOG/217.tif\n",
      "./HOG/218.tif\n",
      "./HOG/219.tif\n",
      "./HOG/220.tif\n",
      "./HOG/221.tif\n",
      "./HOG/222.tif\n",
      "./HOG/223.tif\n",
      "./HOG/224.tif\n",
      "./HOG/225.tif\n",
      "./HOG/226.tif\n",
      "./HOG/227.tif\n",
      "./HOG/228.tif\n",
      "./HOG/229.tif\n",
      "./HOG/230.tif\n",
      "./HOG/231.tif\n",
      "./HOG/232.tif\n",
      "./HOG/233.tif\n",
      "./HOG/234.tif\n",
      "./HOG/235.tif\n",
      "./HOG/236.tif\n",
      "./HOG/237.tif\n",
      "./HOG/238.tif\n",
      "./HOG/239.tif\n",
      "./HOG/240.tif\n",
      "./HOG/241.tif\n",
      "./HOG/242.tif\n",
      "./HOG/243.tif\n",
      "./HOG/244.tif\n",
      "./HOG/245.tif\n",
      "./HOG/246.tif\n",
      "./HOG/247.tif\n",
      "./LOG/1.tif\n",
      "./LOG/2.tif\n",
      "./LOG/3.tif\n",
      "./LOG/4.tif\n",
      "./LOG/5.tif\n",
      "./LOG/6.tif\n",
      "./LOG/7.tif\n",
      "./LOG/8.tif\n",
      "./LOG/9.tif\n",
      "./LOG/10.tif\n",
      "./LOG/11.tif\n",
      "./LOG/12.tif\n",
      "./LOG/13.tif\n",
      "./LOG/14.tif\n",
      "./LOG/15.tif\n",
      "./LOG/16.tif\n",
      "./LOG/17.tif\n",
      "./LOG/18.tif\n",
      "./LOG/19.tif\n",
      "./LOG/20.tif\n",
      "./LOG/21.tif\n",
      "./LOG/22.tif\n",
      "./LOG/23.tif\n",
      "./LOG/24.tif\n",
      "./LOG/25.tif\n",
      "./LOG/26.tif\n",
      "./LOG/27.tif\n",
      "./LOG/28.tif\n",
      "./LOG/29.tif\n",
      "./LOG/30.tif\n",
      "./LOG/31.tif\n",
      "./LOG/32.tif\n",
      "./LOG/33.tif\n",
      "./LOG/34.tif\n",
      "./LOG/35.tif\n",
      "./LOG/36.tif\n",
      "./LOG/37.tif\n",
      "./LOG/38.tif\n",
      "./LOG/39.tif\n",
      "./LOG/40.tif\n",
      "./LOG/41.tif\n",
      "./LOG/42.tif\n",
      "./LOG/43.tif\n",
      "./LOG/44.tif\n",
      "./LOG/45.tif\n",
      "./LOG/46.tif\n",
      "./LOG/47.tif\n",
      "./LOG/48.tif\n",
      "./LOG/49.tif\n",
      "./LOG/50.tif\n",
      "./LOG/51.tif\n",
      "./LOG/52.tif\n",
      "./LOG/53.tif\n",
      "./LOG/54.tif\n",
      "./LOG/55.tif\n",
      "./LOG/56.tif\n",
      "./LOG/57.tif\n",
      "./LOG/58.tif\n",
      "./LOG/59.tif\n",
      "./LOG/60.tif\n",
      "./LOG/61.tif\n",
      "./LOG/62.tif\n",
      "./LOG/63.tif\n",
      "./LOG/64.tif\n",
      "./LOG/65.tif\n",
      "./LOG/66.tif\n",
      "./LOG/67.tif\n",
      "./LOG/68.tif\n",
      "./LOG/69.tif\n",
      "./LOG/70.tif\n",
      "./LOG/71.tif\n",
      "./LOG/72.tif\n",
      "./LOG/73.tif\n",
      "./LOG/74.tif\n",
      "./LOG/75.tif\n",
      "./LOG/76.tif\n",
      "./LOG/77.tif\n",
      "./LOG/78.tif\n",
      "./LOG/79.tif\n",
      "./LOG/80.tif\n",
      "./LOG/81.tif\n",
      "./LOG/82.tif\n",
      "./LOG/83.tif\n",
      "./LOG/84.tif\n",
      "./LOG/85.tif\n",
      "./LOG/86.tif\n",
      "./LOG/87.tif\n",
      "./LOG/88.tif\n",
      "./LOG/89.tif\n",
      "./LOG/90.tif\n",
      "./LOG/91.tif\n",
      "./LOG/92.tif\n",
      "./LOG/93.tif\n",
      "./LOG/94.tif\n",
      "./LOG/95.tif\n",
      "./LOG/96.tif\n",
      "./LOG/97.tif\n",
      "./LOG/98.tif\n",
      "./LOG/99.tif\n",
      "./LOG/100.tif\n",
      "./LOG/101.tif\n",
      "./LOG/102.tif\n",
      "./LOG/103.tif\n",
      "./LOG/104.tif\n",
      "./LOG/105.tif\n",
      "./LOG/106.tif\n",
      "./LOG/107.tif\n",
      "./LOG/108.tif\n",
      "./LOG/109.tif\n",
      "./LOG/110.tif\n",
      "./LOG/111.tif\n",
      "./LOG/112.tif\n",
      "./LOG/113.tif\n",
      "./LOG/114.tif\n",
      "./LOG/115.tif\n",
      "./LOG/116.tif\n",
      "./LOG/117.tif\n",
      "./LOG/118.tif\n",
      "./LOG/119.tif\n",
      "./LOG/120.tif\n",
      "./LOG/121.tif\n",
      "./LOG/122.tif\n",
      "./LOG/123.tif\n",
      "./LOG/124.tif\n",
      "./LOG/125.tif\n",
      "./LOG/126.tif\n",
      "./LOG/127.tif\n",
      "./LOG/128.tif\n",
      "./LOG/129.tif\n",
      "./LOG/130.tif\n",
      "./LOG/131.tif\n",
      "./LOG/132.tif\n",
      "./LOG/133.tif\n",
      "./LOG/134.tif\n",
      "./LOG/135.tif\n",
      "./LOG/136.tif\n",
      "./LOG/137.tif\n",
      "./LOG/138.tif\n",
      "./LOG/139.tif\n",
      "./LOG/140.tif\n",
      "./LOG/141.tif\n",
      "./LOG/142.tif\n",
      "./LOG/143.tif\n",
      "./LOG/144.tif\n",
      "./LOG/145.tif\n",
      "./LOG/146.tif\n",
      "./LOG/147.tif\n",
      "./LOG/148.tif\n",
      "./LOG/149.tif\n",
      "./LOG/150.tif\n",
      "./LOG/151.tif\n",
      "./LOG/152.tif\n",
      "./LOG/153.tif\n",
      "./LOG/154.tif\n",
      "./LOG/155.tif\n",
      "./LOG/156.tif\n",
      "./LOG/157.tif\n",
      "./LOG/158.tif\n",
      "./LOG/159.tif\n",
      "./LOG/160.tif\n",
      "./LOG/161.tif\n",
      "./LOG/162.tif\n",
      "./LOG/163.tif\n",
      "./LOG/164.tif\n",
      "./LOG/165.tif\n",
      "./LOG/166.tif\n",
      "./LOG/167.tif\n",
      "./LOG/168.tif\n",
      "./LOG/169.tif\n",
      "./LOG/170.tif\n",
      "./LOG/171.tif\n",
      "./LOG/172.tif\n",
      "./LOG/173.tif\n",
      "./LOG/174.tif\n",
      "./LOG/175.tif\n",
      "./LOG/176.tif\n",
      "./LOG/177.tif\n",
      "./LOG/178.tif\n",
      "./LOG/179.tif\n",
      "./LOG/180.tif\n",
      "./LOG/181.tif\n",
      "./LOG/182.tif\n",
      "./LOG/183.tif\n",
      "./LOG/184.tif\n",
      "./LOG/185.tif\n",
      "./LOG/186.tif\n",
      "./LOG/187.tif\n",
      "./LOG/188.tif\n",
      "./LOG/189.tif\n",
      "./LOG/190.tif\n",
      "./LOG/191.tif\n",
      "./LOG/192.tif\n",
      "./LOG/193.tif\n",
      "./LOG/194.tif\n",
      "./LOG/195.tif\n",
      "./LOG/196.tif\n",
      "./LOG/197.tif\n",
      "./LOG/198.tif\n",
      "./LOG/199.tif\n",
      "./LOG/200.tif\n",
      "./LOG/201.tif\n",
      "./LOG/202.tif\n",
      "./LOG/203.tif\n",
      "./LOG/204.tif\n",
      "./LOG/205.tif\n",
      "./LOG/206.tif\n",
      "./LOG/207.tif\n",
      "./LOG/208.tif\n",
      "./LOG/209.tif\n",
      "./LOG/210.tif\n",
      "./LOG/211.tif\n",
      "./LOG/212.tif\n",
      "./LOG/213.tif\n",
      "./LOG/214.tif\n",
      "./LOG/215.tif\n",
      "./LOG/216.tif\n",
      "./LOG/217.tif\n",
      "./LOG/218.tif\n",
      "./LOG/219.tif\n",
      "./LOG/220.tif\n",
      "./LOG/221.tif\n",
      "./LOG/222.tif\n",
      "./LOG/223.tif\n",
      "./LOG/224.tif\n",
      "./LOG/225.tif\n",
      "./LOG/226.tif\n",
      "./LOG/227.tif\n",
      "./LOG/228.tif\n",
      "./LOG/229.tif\n",
      "./LOG/230.tif\n",
      "./LOG/231.tif\n",
      "./LOG/232.tif\n",
      "./LOG/233.tif\n",
      "./LOG/234.tif\n",
      "./LOG/235.tif\n",
      "./LOG/236.tif\n",
      "./LOG/237.tif\n",
      "./LOG/238.tif\n",
      "./LOG/239.tif\n",
      "./LOG/240.tif\n",
      "./LOG/241.tif\n",
      "./LOG/242.tif\n",
      "./LOG/243.tif\n",
      "./LOG/244.tif\n",
      "./LOG/245.tif\n",
      "./LOG/246.tif\n",
      "./LOG/247.tif\n",
      "./Gabor/1.tif\n",
      "./Gabor/2.tif\n",
      "./Gabor/3.tif\n",
      "./Gabor/4.tif\n",
      "./Gabor/5.tif\n",
      "./Gabor/6.tif\n",
      "./Gabor/7.tif\n",
      "./Gabor/8.tif\n",
      "./Gabor/9.tif\n",
      "./Gabor/10.tif\n",
      "./Gabor/11.tif\n",
      "./Gabor/12.tif\n",
      "./Gabor/13.tif\n",
      "./Gabor/14.tif\n",
      "./Gabor/15.tif\n",
      "./Gabor/16.tif\n",
      "./Gabor/17.tif\n",
      "./Gabor/18.tif\n",
      "./Gabor/19.tif\n",
      "./Gabor/20.tif\n",
      "./Gabor/21.tif\n",
      "./Gabor/22.tif\n",
      "./Gabor/23.tif\n",
      "./Gabor/24.tif\n",
      "./Gabor/25.tif\n",
      "./Gabor/26.tif\n",
      "./Gabor/27.tif\n",
      "./Gabor/28.tif\n",
      "./Gabor/29.tif\n",
      "./Gabor/30.tif\n",
      "./Gabor/31.tif\n",
      "./Gabor/32.tif\n",
      "./Gabor/33.tif\n",
      "./Gabor/34.tif\n",
      "./Gabor/35.tif\n",
      "./Gabor/36.tif\n",
      "./Gabor/37.tif\n",
      "./Gabor/38.tif\n",
      "./Gabor/39.tif\n",
      "./Gabor/40.tif\n",
      "./Gabor/41.tif\n",
      "./Gabor/42.tif\n",
      "./Gabor/43.tif\n",
      "./Gabor/44.tif\n",
      "./Gabor/45.tif\n",
      "./Gabor/46.tif\n",
      "./Gabor/47.tif\n",
      "./Gabor/48.tif\n",
      "./Gabor/49.tif\n",
      "./Gabor/50.tif\n",
      "./Gabor/51.tif\n",
      "./Gabor/52.tif\n",
      "./Gabor/53.tif\n",
      "./Gabor/54.tif\n",
      "./Gabor/55.tif\n",
      "./Gabor/56.tif\n",
      "./Gabor/57.tif\n",
      "./Gabor/58.tif\n",
      "./Gabor/59.tif\n",
      "./Gabor/60.tif\n",
      "./Gabor/61.tif\n",
      "./Gabor/62.tif\n",
      "./Gabor/63.tif\n",
      "./Gabor/64.tif\n",
      "./Gabor/65.tif\n",
      "./Gabor/66.tif\n",
      "./Gabor/67.tif\n",
      "./Gabor/68.tif\n",
      "./Gabor/69.tif\n",
      "./Gabor/70.tif\n",
      "./Gabor/71.tif\n",
      "./Gabor/72.tif\n",
      "./Gabor/73.tif\n",
      "./Gabor/74.tif\n",
      "./Gabor/75.tif\n",
      "./Gabor/76.tif\n",
      "./Gabor/77.tif\n",
      "./Gabor/78.tif\n",
      "./Gabor/79.tif\n",
      "./Gabor/80.tif\n",
      "./Gabor/81.tif\n",
      "./Gabor/82.tif\n",
      "./Gabor/83.tif\n",
      "./Gabor/84.tif\n",
      "./Gabor/85.tif\n",
      "./Gabor/86.tif\n",
      "./Gabor/87.tif\n",
      "./Gabor/88.tif\n",
      "./Gabor/89.tif\n",
      "./Gabor/90.tif\n",
      "./Gabor/91.tif\n",
      "./Gabor/92.tif\n",
      "./Gabor/93.tif\n",
      "./Gabor/94.tif\n",
      "./Gabor/95.tif\n",
      "./Gabor/96.tif\n",
      "./Gabor/97.tif\n",
      "./Gabor/98.tif\n",
      "./Gabor/99.tif\n",
      "./Gabor/100.tif\n",
      "./Gabor/101.tif\n",
      "./Gabor/102.tif\n",
      "./Gabor/103.tif\n",
      "./Gabor/104.tif\n",
      "./Gabor/105.tif\n",
      "./Gabor/106.tif\n",
      "./Gabor/107.tif\n",
      "./Gabor/108.tif\n",
      "./Gabor/109.tif\n",
      "./Gabor/110.tif\n",
      "./Gabor/111.tif\n",
      "./Gabor/112.tif\n",
      "./Gabor/113.tif\n",
      "./Gabor/114.tif\n",
      "./Gabor/115.tif\n",
      "./Gabor/116.tif\n",
      "./Gabor/117.tif\n",
      "./Gabor/118.tif\n",
      "./Gabor/119.tif\n",
      "./Gabor/120.tif\n",
      "./Gabor/121.tif\n",
      "./Gabor/122.tif\n",
      "./Gabor/123.tif\n",
      "./Gabor/124.tif\n",
      "./Gabor/125.tif\n",
      "./Gabor/126.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Gabor/127.tif\n",
      "./Gabor/128.tif\n",
      "./Gabor/129.tif\n",
      "./Gabor/130.tif\n",
      "./Gabor/131.tif\n",
      "./Gabor/132.tif\n",
      "./Gabor/133.tif\n",
      "./Gabor/134.tif\n",
      "./Gabor/135.tif\n",
      "./Gabor/136.tif\n",
      "./Gabor/137.tif\n",
      "./Gabor/138.tif\n",
      "./Gabor/139.tif\n",
      "./Gabor/140.tif\n",
      "./Gabor/141.tif\n",
      "./Gabor/142.tif\n",
      "./Gabor/143.tif\n",
      "./Gabor/144.tif\n",
      "./Gabor/145.tif\n",
      "./Gabor/146.tif\n",
      "./Gabor/147.tif\n",
      "./Gabor/148.tif\n",
      "./Gabor/149.tif\n",
      "./Gabor/150.tif\n",
      "./Gabor/151.tif\n",
      "./Gabor/152.tif\n",
      "./Gabor/153.tif\n",
      "./Gabor/154.tif\n",
      "./Gabor/155.tif\n",
      "./Gabor/156.tif\n",
      "./Gabor/157.tif\n",
      "./Gabor/158.tif\n",
      "./Gabor/159.tif\n",
      "./Gabor/160.tif\n",
      "./Gabor/161.tif\n",
      "./Gabor/162.tif\n",
      "./Gabor/163.tif\n",
      "./Gabor/164.tif\n",
      "./Gabor/165.tif\n",
      "./Gabor/166.tif\n",
      "./Gabor/167.tif\n",
      "./Gabor/168.tif\n",
      "./Gabor/169.tif\n",
      "./Gabor/170.tif\n",
      "./Gabor/171.tif\n",
      "./Gabor/172.tif\n",
      "./Gabor/173.tif\n",
      "./Gabor/174.tif\n",
      "./Gabor/175.tif\n",
      "./Gabor/176.tif\n",
      "./Gabor/177.tif\n",
      "./Gabor/178.tif\n",
      "./Gabor/179.tif\n",
      "./Gabor/180.tif\n",
      "./Gabor/181.tif\n",
      "./Gabor/182.tif\n",
      "./Gabor/183.tif\n",
      "./Gabor/184.tif\n",
      "./Gabor/185.tif\n",
      "./Gabor/186.tif\n",
      "./Gabor/187.tif\n",
      "./Gabor/188.tif\n",
      "./Gabor/189.tif\n",
      "./Gabor/190.tif\n",
      "./Gabor/191.tif\n",
      "./Gabor/192.tif\n",
      "./Gabor/193.tif\n",
      "./Gabor/194.tif\n",
      "./Gabor/195.tif\n",
      "./Gabor/196.tif\n",
      "./Gabor/197.tif\n",
      "./Gabor/198.tif\n",
      "./Gabor/199.tif\n",
      "./Gabor/200.tif\n",
      "./Gabor/201.tif\n",
      "./Gabor/202.tif\n",
      "./Gabor/203.tif\n",
      "./Gabor/204.tif\n",
      "./Gabor/205.tif\n",
      "./Gabor/206.tif\n",
      "./Gabor/207.tif\n",
      "./Gabor/208.tif\n",
      "./Gabor/209.tif\n",
      "./Gabor/210.tif\n",
      "./Gabor/211.tif\n",
      "./Gabor/212.tif\n",
      "./Gabor/213.tif\n",
      "./Gabor/214.tif\n",
      "./Gabor/215.tif\n",
      "./Gabor/216.tif\n",
      "./Gabor/217.tif\n",
      "./Gabor/218.tif\n",
      "./Gabor/219.tif\n",
      "./Gabor/220.tif\n",
      "./Gabor/221.tif\n",
      "./Gabor/222.tif\n",
      "./Gabor/223.tif\n",
      "./Gabor/224.tif\n",
      "./Gabor/225.tif\n",
      "./Gabor/226.tif\n",
      "./Gabor/227.tif\n",
      "./Gabor/228.tif\n",
      "./Gabor/229.tif\n",
      "./Gabor/230.tif\n",
      "./Gabor/231.tif\n",
      "./Gabor/232.tif\n",
      "./Gabor/233.tif\n",
      "./Gabor/234.tif\n",
      "./Gabor/235.tif\n",
      "./Gabor/236.tif\n",
      "./Gabor/237.tif\n",
      "./Gabor/238.tif\n",
      "./Gabor/239.tif\n",
      "./Gabor/240.tif\n",
      "./Gabor/241.tif\n",
      "./Gabor/242.tif\n",
      "./Gabor/243.tif\n",
      "./Gabor/244.tif\n",
      "./Gabor/245.tif\n",
      "./Gabor/246.tif\n",
      "./Gabor/247.tif\n",
      "Training... \n",
      "Train on 148 samples, validate on 74 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2f2845c434bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m \u001b[0mProb_dataset_as_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_imagedata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProb_dataset_as_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m# Create empty DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-2f2845c434bb>\u001b[0m in \u001b[0;36mrunCNN\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training... \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;31m# show_traingraph(hist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape=(32, 32,1)\n",
    "num_classes=2\n",
    "class_weight = {0: 3,1: 1.}\n",
    "splits=10\n",
    "\n",
    "\n",
    "# compile the CNN here\n",
    "def compileCNN():\n",
    "    x = keras.layers.Input(input_shape)\n",
    "    model = keras_resnet.models.ResNet50(x, classes=num_classes)\n",
    "    model.compile(\"adam\",\"binary_crossentropy\", [\"accuracy\",f1_m],)\n",
    "    return model\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Given the ing link data\n",
    "# read each image and resize to 32x32\n",
    "def collectImageData(data):\n",
    "    for feature in range(0, 4):\n",
    "        for idx, file in enumerate(data[:, feature]):\n",
    "#             print(file)\n",
    "            img = cv2.imread(file,0)\n",
    "            resized = resize(img, input_shape)\n",
    "            data[idx, feature] = resized\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def show_traingraph(history):\n",
    "    # list all data in history\n",
    "    # print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# Run the CNN\n",
    "def runCNN(data):\n",
    "\n",
    "    kf = KFold(n_splits=splits)\n",
    "\n",
    "    Prob_dataset = []\n",
    "\n",
    "    for feature in range(0, 4):\n",
    "\n",
    "        # compute new model for each feature\n",
    "        model = compileCNN()\n",
    "\n",
    "        accuracy_sum = 0\n",
    "        fscore_sum = 0\n",
    "        FNR_sum = 0\n",
    "        FDR_sum = 0\n",
    "        SPC_sum = 0\n",
    "\n",
    "        Probability_as_Feature = []\n",
    "\n",
    "        for train, test in kf.split(data):\n",
    "            train_size = len(train)\n",
    "            test_size = len(test)\n",
    "\n",
    "            x_train = np.empty((train_size,32, 32,1))\n",
    "            y_train = to_categorical(data[train,4],num_classes=2)\n",
    "\n",
    "            # compute class weight\n",
    "            # class_weight[0] =  train_size / sum(data[train, 4])\n",
    "\n",
    "            y_test = data[test, 4]\n",
    "\n",
    "            for i in range(train_size):\n",
    "                x_train[i] = data[i,feature]/255\n",
    "\n",
    "            x_test = np.empty((test_size, 32, 32,1))\n",
    "            for i in range(test_size):\n",
    "                x_test[i] = data[i, feature]/255\n",
    "\n",
    "            print(\"Training... \")\n",
    "            hist = model.fit(x_train, y_train, batch_size=100, epochs=10, validation_split=0.33, shuffle= True, class_weight=class_weight,verbose=1)\n",
    "            # show_traingraph(hist)\n",
    "\n",
    "            probs = model.predict(x_test, batch_size=64)\n",
    "\n",
    "\n",
    "            # test sets are done in sequential order, so we can do this here\n",
    "            for prob in probs:\n",
    "                Probability_as_Feature.append(prob[0])\n",
    "\n",
    "\n",
    "            y_pred_bool = np.argmax(probs, axis=1).astype(int)\n",
    "\n",
    "            y_actu = pd.Series(y_test, name='Actual')\n",
    "            y_pred = pd.Series(y_pred_bool, name='Predicted')\n",
    "\n",
    "            df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "            print(df_confusion)\n",
    "\n",
    "\n",
    "            #Check if confusion matrix is 2x2\n",
    "            empty_class = [0, 0]\n",
    "            if '0' not in df_confusion.columns:\n",
    "                df_confusion['0'] = empty_class\n",
    "            if '1' not in df_confusion.columns:\n",
    "                df_confusion['1'] = empty_class\n",
    "\n",
    "            # Calc all metrics\n",
    "            fscore, FNR, FDR, SPC, ACC = calcMetrics(np.asarray(df_confusion))\n",
    "            accuracy_sum = accuracy_sum + ACC\n",
    "            fscore_sum = fscore_sum + fscore\n",
    "            FNR_sum = FNR_sum + FNR\n",
    "            FDR_sum = FDR_sum + FDR\n",
    "            SPC_sum = SPC_sum + SPC\n",
    "        accuracy_average = accuracy_sum / splits\n",
    "        fscore_avg = fscore_sum / splits\n",
    "        FNR_avg = FNR_sum / splits\n",
    "        FDR_avg = FDR_sum / splits\n",
    "        SPC_avg = SPC_sum / splits\n",
    "\n",
    "\n",
    "        print(\"\\nFeature: \" + str(feature))\n",
    "        print(\"Average F-score: \" + str(fscore_avg))\n",
    "        print(\"Average Accuracy: \" + str(accuracy_average))\n",
    "        print(\"Average False Negative Rate: \" + str(FNR_avg))\n",
    "        print(\"Average Selectivity: \" + str(SPC_avg))\n",
    "        print(\"Average False Discovery Rate: \" + str(FDR_avg)+\"\\n\")\n",
    "\n",
    "        stat_array = [feature,fscore_avg,accuracy_average,FNR_avg,SPC_avg,FDR_avg]\n",
    "\n",
    "\n",
    "        with open(\"resnet_test_\"+str(feature)+\".csv\", \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(stat_array)\n",
    "\n",
    "        # print(Probability_as_Feature)\n",
    "        Prob_dataset.append(Probability_as_Feature)\n",
    "\n",
    "    return Prob_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NOTE we do not need to scale the features as we are using a decision based algorithm\n",
    "\n",
    "dataset = pd.read_csv(\"./dataset_report.csv\")\n",
    "dataset= dataset.replace(\"Healthy\",1)\n",
    "dataset = dataset.replace(\"Damaged\",0)\n",
    "\n",
    "meta_headers = ['Cropped Frame','Original Frame', \"HOG\",\"Laplace of Gaussian\",\"Gabor Wavelet\",\"SIFT\",\"Centroid_x\",\"Centroid_y\"]\n",
    "CNN_HEADERS = ['Cropped Frame',\"HOG\",\"Laplace of Gaussian\",\"Gabor Wavelet\",\"True Classification\"]\n",
    "CNN_data = dataset[CNN_HEADERS]\n",
    "CNN_data['Cropped Frame Location'] = dataset['Cropped Frame'].values\n",
    "CNN_data = np.array(CNN_data)\n",
    "\n",
    "# Shuffle the data so that the K folds are not to be influenced by the original frame\n",
    "# np.random.shuffle(CNN_data)\n",
    "\n",
    "shuffled_cropped_image_locations = CNN_data[:,5]\n",
    "# print(shuffled_cropped_image_locations)\n",
    "\n",
    "CNN_imagedata = collectImageData(CNN_data)\n",
    "\n",
    "\n",
    "Prob_dataset_as_lists = runCNN(CNN_imagedata)\n",
    "# print(Prob_dataset_as_lists)\n",
    "# Create empty DF\n",
    "\n",
    "Join_headers = ['Cropped Frame','Cropped Frame_prob',\"HOG_prob\",\"Laplace of Gaussian_prob\",\"Gabor Wavelet_prob\"]\n",
    "my_df = pd.DataFrame(columns = Join_headers)\n",
    "my_df['Cropped Frame'] = shuffled_cropped_image_locations\n",
    "my_df['Cropped Frame_prob'] = Prob_dataset_as_lists[0]\n",
    "my_df['HOG_prob'] = Prob_dataset_as_lists[1]\n",
    "my_df['Laplace of Gaussian_prob'] = Prob_dataset_as_lists[2]\n",
    "my_df['Gabor Wavelet_prob'] = Prob_dataset_as_lists[3]\n",
    "# probs_as_df = pd.DataFrame(data=Prob_dataset,columns=CNN_HEADERS)\n",
    "\n",
    "dataset = pd.merge(my_df,dataset, on=['Cropped Frame'])\n",
    "\n",
    "print(dataset['Cropped Frame_prob'])\n",
    "\n",
    "\n",
    "dataset.to_csv('Dataset_ensable_new.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits=10\n",
    "kf = KFold(n_splits=splits)\n",
    "accuracy_sum = 0\n",
    "fscore_sum = 0\n",
    "FNR_sum = 0\n",
    "FDR_sum = 0\n",
    "SPC_sum = 0\n",
    "\n",
    "report_location = \"featureselection_2d.csv\"\n",
    "if os.path.isfile(report_location):\n",
    "    os.remove(report_location)\n",
    "# NOTE we do not need to scale the features as we are using a decision based algorithm\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"./Dataset_ensable_new.csv\")\n",
    "\n",
    "clone = dataset.copy(deep=True)\n",
    "\n",
    "\n",
    "dataset= dataset.replace(\"Healthy\",1)\n",
    "dataset = dataset.replace(\"Damaged\",0)\n",
    "\n",
    "meta_headers = ['Cropped Frame','Original Frame', \"HOG\",\"Laplace of Gaussian\",\"Gabor Wavelet\",\"Centroid_x\",\"Centroid_y\"]\n",
    "SIFT = dataset.filter(regex=(\"SIFT.*\"))\n",
    "\n",
    "\n",
    "LBP = dataset.filter(regex=(\"Linear Binary Patterns.*\"))\n",
    "dataset.drop(SIFT, axis=1, inplace=True)\n",
    "dataset.drop(LBP, axis=1, inplace=True)\n",
    "ZLM = dataset.filter(regex=(\"Zernlike Moments.*\"))\n",
    "dataset.drop(ZLM, axis=1, inplace=True)\n",
    "# meta_data = dataset.filter(meta_headers, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "meta_data = dataset.filter(meta_headers, axis=1)\n",
    "dataset.drop(meta_headers, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.fillna(0)\n",
    "\n",
    "\n",
    "# move classes to first column\n",
    "mid = dataset['True Classification']\n",
    "# print(mid)\n",
    "dataset.drop(labels=['True Classification'], axis=1,inplace = True)\n",
    "\n",
    "head = np.array(dataset.columns.values)\n",
    "\n",
    "dataset.insert(0, 'True Classification', mid)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(dataset)\n",
    "# df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "dataset = np.array(df)\n",
    "\n",
    "pred_classifications = []\n",
    "\n",
    "# Shuffle the data so that the K folds are not to be influenced by the original frame\n",
    "# np.random.shuffle(dataset)\n",
    "\n",
    "X = dataset[:, 1:]\n",
    "y = dataset[:, 0]\n",
    "\n",
    "max_features = min(X.shape[1],X.shape[0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "for train, test in kf.split(dataset):\n",
    "    X_train = dataset[train][:,1:]\n",
    "\n",
    "    X_test = dataset[test][:,1:]\n",
    "    y_train = dataset[train][:,0]\n",
    "\n",
    "    y_test = dataset[test][:,0]\n",
    "\n",
    "\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "\n",
    "\n",
    "    regressor = RandomForestClassifier(n_estimators=100, random_state=2, max_depth=10, criterion='gini', max_features=max_features,)\n",
    "    regressor.fit(X_train, training_scores_encoded)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "    for prediction in y_pred:\n",
    "        pred_classifications.append(prediction)\n",
    "\n",
    "    '''\n",
    "    importances = regressor.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in regressor.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %s (%f)\" % (f + 1, head[indices[f]], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "            color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    fscore, FNR, FDR, SPC, ACC = calcMetrics(conf_mat)\n",
    "\n",
    "\n",
    "    accuracy_sum = accuracy_sum + ACC\n",
    "    fscore_sum = fscore_sum + fscore\n",
    "    FNR_sum = FNR_sum + FNR\n",
    "    FDR_sum = FDR_sum + FDR\n",
    "    SPC_sum = SPC_sum + SPC\n",
    "\n",
    "\n",
    "accuracy_average = accuracy_sum/splits\n",
    "fscore_avg = fscore_sum/splits\n",
    "FNR_avg = FNR_sum/splits\n",
    "FDR_avg = FDR_sum/splits\n",
    "SPC_avg = SPC_sum/splits\n",
    "\n",
    "print(\"Average F-score: \" + str(fscore_avg))\n",
    "print(\"Average Accuracy: \" + str(accuracy_average))\n",
    "print(\"Average False Negative Rate: \" + str(FNR_avg))\n",
    "print(\"Average Specificity: \" + str(SPC_avg))\n",
    "print(\"Average False Discovery Rate: \" + str(FDR_avg))\n",
    "\n",
    "\n",
    "# dataset = pd.read_csv(\"./Dataset_ensable_new.csv\")\n",
    "clone[\"Pred Classifications\"] = pred_classifications\n",
    "clone.to_csv(\"./dataset_ensable_predclasses.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = pd.read_csv(\"./dataset_ensable_predclasses.csv\")\n",
    "\n",
    "\n",
    "meta_headers = ['Cropped Frame','Original Frame', \"HOG\",\"Laplace of Gaussian\",\"Gabor Wavelet\",\"Centroid_x\",\"Centroid_y\"]\n",
    "SIFT = dataset.filter(regex=(\"SIFT.*\"))\n",
    "LBP = dataset.filter(regex=(\"Linear Binary Patterns.*\"))\n",
    "# dataset.drop(SIFT, axis=1, inplace=True)\n",
    "# dataset.drop(LBP, axis=1, inplace=True)\n",
    "\n",
    "meta_data = dataset.filter(meta_headers, axis=1)\n",
    "dataset.drop(meta_headers, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "dataset= dataset.replace(\"Healthy\",1)\n",
    "dataset = dataset.replace(\"Damaged\",0)\n",
    "\n",
    "dataset = dataset.fillna(0)\n",
    "\n",
    "\n",
    "# move classes to first column\n",
    "TC = dataset['True Classification']\n",
    "dataset.drop(labels=['True Classification'], axis=1, inplace = True)\n",
    "\n",
    "PC = dataset[\"Pred Classifications\"]\n",
    "dataset.drop(labels=['Pred Classifications'], axis=1, inplace = True)\n",
    "\n",
    "#convet True classes and predicted classes into 1,2,3,4 based on TP,TN,FP,FN\n",
    "\n",
    "PC = np.array(PC,dtype=int)\n",
    "TC = np.array(TC,dtype=int)\n",
    "color_labels = np.empty(shape=(TC.shape[0],1))\n",
    "\n",
    "for data_point in range(TC.shape[0]):\n",
    "    if TC[data_point] == 1 and PC[data_point] == 1:\n",
    "        # True Positive\n",
    "        color_labels[data_point] = 0\n",
    "    elif TC[data_point] == 0 and PC[data_point] == 1:\n",
    "        # False Negative\n",
    "        color_labels[data_point] = 1\n",
    "    elif TC[data_point] == 1 and PC[data_point] == 0:\n",
    "        # False Positive\n",
    "        color_labels[data_point] = 2\n",
    "    else:\n",
    "        # True Negative\n",
    "        color_labels[data_point] = 3\n",
    "\n",
    "print(color_labels)\n",
    "color_df = dataset.copy(deep=True)\n",
    "color_df.insert(0, 'Color Classification', color_labels)\n",
    "\n",
    "color_df = np.array(color_df,dtype=float)\n",
    "# Initialise the Scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(color_df)\n",
    "color_df = scaler.transform(color_df)\n",
    "\n",
    "\n",
    "\n",
    "# Shuffle the data so that the K folds are not to be influenced by the original frame\n",
    "np.random.shuffle(color_df)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X_train = color_df[:,1:]\n",
    "X_test = color_df[:,1:]\n",
    "y_train = color_df[:,0]\n",
    "y_test = color_df[:,0]\n",
    "\n",
    "pca.fit(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# import matplotlib.collections.PathCollection.legend_elements\n",
    "\n",
    "# print(X_train)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xlabel('Principal Component 1', fontsize=15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize=15)\n",
    "ax.set_title('2 component PCA', fontsize=20)\n",
    "targets = ['TP', 'FN','FP','TN']\n",
    "colors = ['g', 'y', 'b','r']\n",
    "\n",
    "\n",
    "scatter = ax.scatter(X_test[:,0]\n",
    "           , X_test[:,1]\n",
    "           , c=y_test\n",
    "           , alpha= 0.3\n",
    "           , s=25\n",
    "           ,cmap= matplotlib.colors.ListedColormap(colors))\n",
    "\n",
    "# todo make legends\n",
    "\n",
    "bounds = np.linspace(0,3,4)\n",
    "cb = plt.colorbar(scatter, spacing='proportional',ticks=bounds)\n",
    "# cb.set_label('Custom cbar')\n",
    "\n",
    "# ax.legend(targets[0])\n",
    "ax.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset.insert(0, 'True Classification', TC)\n",
    "\n",
    "dataset = np.array(dataset,dtype=float)\n",
    "\n",
    "# Initialise the Scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset)\n",
    "dataset = scaler.transform(dataset)\n",
    "\n",
    "\n",
    "\n",
    "# Shuffle the data so that the K folds are not to be influenced by the original frame\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X_train = dataset[:,1:]\n",
    "X_test = dataset[:,1:]\n",
    "y_train = dataset[:,0]\n",
    "y_test = dataset[:,0]\n",
    "\n",
    "pca.fit(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# print(X_train)\n",
    "fig1 = plt.figure(figsize=(8, 8))\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "ax1.set_xlabel('Principal Component 1', fontsize=15)\n",
    "ax1.set_ylabel('Principal Component 2', fontsize=15)\n",
    "ax1.set_title('2 component PCA', fontsize=20)\n",
    "targets = ['TP', 'TN']\n",
    "colors = ['r', 'g']\n",
    "\n",
    "# for target, color in zip(targets, colors):\n",
    "scatter = ax1.scatter(X_test[:,0]\n",
    "           , X_test[:,1]\n",
    "           , c= y_test\n",
    "           , s= 25\n",
    "           , alpha= 0.3\n",
    "           , cmap= matplotlib.colors.ListedColormap(colors))\n",
    "\n",
    "bounds = np.linspace(0,1,2)\n",
    "cb = plt.colorbar(scatter, spacing='proportional',ticks=bounds)\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IMAGE_SIZE = 20\n",
    "\n",
    "def read_and_resizeimage(img_src):\n",
    "    img = cv2.imread(img_src,0)\n",
    "    img = cv2.resize(img,(32,32))\n",
    "    return img\n",
    "\n",
    "import math\n",
    "\n",
    "def appendImage(tiny_img,large_image,y_offset,x_offset,pred_class):\n",
    "    rows = tiny_img.shape[0]\n",
    "    cols = tiny_img.shape[1]\n",
    "    for x in range(0, rows-1):\n",
    "        for y in range(0, cols-1):\n",
    "            large_image[int(x+x_offset), int(y+y_offset),pred_class+1] = int(tiny_img[x,y])\n",
    "    return  large_image\n",
    "\n",
    "\n",
    "\n",
    "def combineImages(df, col=12, rows=12, size=32):\n",
    "    # Width is constant, Height is defined by how many images it can fit.\n",
    "    #\n",
    "    # Num per row =\n",
    "    height = rows*size\n",
    "    width = col*size\n",
    "\n",
    "    img_arr = np.zeros((height, width,3),dtype=int)\n",
    "\n",
    "    y_offset = 0\n",
    "    x_offset = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        print(x_offset)\n",
    "        print(y_offset)\n",
    "\n",
    "        img_src = row['Cropped Frame']\n",
    "        pred_class = abs(row['Pred Classifications']-1)\n",
    "        img = read_and_resizeimage(img_src)\n",
    "\n",
    "        img_arr = appendImage(img, img_arr, y_offset, x_offset,pred_class)\n",
    "\n",
    "        # calc new offset\n",
    "        # print(index)\n",
    "        scale = int(math.fmod(index,rows))\n",
    "        print(scale)\n",
    "        x_offset += size\n",
    "\n",
    "        if(x_offset==width):\n",
    "            y_offset+=size\n",
    "            x_offset = 0\n",
    "\n",
    "\n",
    "    return img_arr\n",
    "\n",
    "\n",
    "\n",
    "# combine images\n",
    "dataset = pd.read_csv(\"./dataset_ensable_predclasses.csv\")\n",
    "wanted_headers = [\"Cropped Frame\",\"True Classification\",\"Pred Classifications\"]\n",
    "meta_data = dataset.filter(wanted_headers, axis=1)\n",
    "is_damaged = meta_data['True Classification'] == 0\n",
    "is_undamaged = meta_data['True Classification'] == 1\n",
    "\n",
    "# the plot number should ideally be a prefect square\n",
    "damaged = meta_data[is_damaged].head(144).reset_index()\n",
    "undamaged = meta_data[is_undamaged].head(144).reset_index()\n",
    "\n",
    "result = combineImages(undamaged)\n",
    "\n",
    "# cv2.imwrite(\"Undamaged.png\", result)\n",
    "\n",
    "result = combineImages(damaged)\n",
    "cv2.imwrite(\"Damaged.png\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
